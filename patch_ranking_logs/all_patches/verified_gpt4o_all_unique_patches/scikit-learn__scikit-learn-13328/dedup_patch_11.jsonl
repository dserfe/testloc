{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13328", "model_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 774a22b..577f9e2 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -8,6 +8,7 @@ from scipy import optimize\n from ..base import BaseEstimator, RegressorMixin\n from .base import LinearModel\n from ..utils import check_X_y\n+from ..utils.validation import check_array\n from ..utils import check_consistent_length\n from ..utils import axis0_safe_slice\n from ..utils.extmath import safe_sparse_dot\n@@ -48,6 +49,7 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n         Returns the derivative of the Huber loss with respect to each\n         coefficient, intercept and the scale as a vector.\n     \"\"\"\n+    X = check_array(X, dtype=[np.float64, np.float32])\n     _, n_features = X.shape\n     fit_intercept = (n_features + 2 == w.shape[0])\n     if fit_intercept:\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 81acf45..eee723c 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -3,10 +3,12 @@ from scipy import optimize\n from ..base import BaseEstimator, RegressorMixin\n from .base import LinearModel\n from ..utils import check_X_y\n+from ..utils.validation import check_array\n from ..utils import check_consistent_length\n from ..utils import axis0_safe_slice\n from ..utils.extmath import safe_sparse_dot\n def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n+    X = check_array(X, dtype=[np.float64, np.float32])\n     _, n_features = X.shape\n     fit_intercept = n_features + 2 == w.shape[0]\n     if fit_intercept:\n", "normalized_occurrence": 1}
