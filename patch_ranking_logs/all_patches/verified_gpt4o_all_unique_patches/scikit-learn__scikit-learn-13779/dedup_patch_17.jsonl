{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13779", "model_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 858d868..c107622 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n-                if not has_fit_parameter(step, 'sample_weight'):\n+                if step is not None and not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n \n@@ -97,7 +97,8 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n \n         self.named_estimators_ = Bunch()\n         for k, e in zip(self.estimators, self.estimators_):\n-            self.named_estimators_[k[0]] = e\n+            if k[1] is not None:\n+                self.named_estimators_[k[0]] = e\n         return self\n \n     def set_params(self, **params):\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex c17361f..0eb9e5e 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -35,7 +35,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n             raise ValueError('Number of `estimators` and weights must be equal; got %d weights, %d estimators' % (len(self.weights), len(self.estimators)))\n         if sample_weight is not None:\n             for name, step in self.estimators:\n-                if not has_fit_parameter(step, 'sample_weight'):\n+                if step is not None and (not has_fit_parameter(step, 'sample_weight')):\n                     raise ValueError(\"Underlying estimator '%s' does not support sample weights.\" % name)\n         names, clfs = zip(*self.estimators)\n         self._validate_names(names)\n@@ -45,7 +45,8 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n         self.estimators_ = Parallel(n_jobs=self.n_jobs)((delayed(_parallel_fit_estimator)(clone(clf), X, y, sample_weight=sample_weight) for clf in clfs if clf is not None))\n         self.named_estimators_ = Bunch()\n         for k, e in zip(self.estimators, self.estimators_):\n-            self.named_estimators_[k[0]] = e\n+            if k[1] is not None:\n+                self.named_estimators_[k[0]] = e\n         return self\n     def set_params(self, **params):\n         return self._set_params('estimators', **params)\n", "normalized_occurrence": 1}
