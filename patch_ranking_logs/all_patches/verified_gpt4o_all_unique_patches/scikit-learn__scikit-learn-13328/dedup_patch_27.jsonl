{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13328", "model_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 774a22b..ef5ba54 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -55,12 +55,18 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n     sigma = w[-1]\n     w = w[:n_features]\n     n_samples = np.sum(sample_weight)\n+    \n+    # Ensure sample_weight is of float type\n+    if sample_weight is not None:\n+        sample_weight = sample_weight.astype(float)\n \n     # Calculate the values where |y - X'w -c / sigma| > epsilon\n     # The values above this threshold are outliers.\n     linear_loss = y - safe_sparse_dot(X, w)\n     if fit_intercept:\n         linear_loss -= intercept\n+    # Ensure X is of float type\n+    X = X.astype(float)\n     abs_linear_loss = np.abs(linear_loss)\n     outliers_mask = abs_linear_loss > epsilon * sigma\n \n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 81acf45..4aa6a03 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -14,9 +14,12 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n     sigma = w[-1]\n     w = w[:n_features]\n     n_samples = np.sum(sample_weight)\n+    if sample_weight is not None:\n+        sample_weight = sample_weight.astype(float)\n     linear_loss = y - safe_sparse_dot(X, w)\n     if fit_intercept:\n         linear_loss -= intercept\n+    X = X.astype(float)\n     abs_linear_loss = np.abs(linear_loss)\n     outliers_mask = abs_linear_loss > epsilon * sigma\n     outliers = abs_linear_loss[outliers_mask]\n", "normalized_occurrence": 1}
