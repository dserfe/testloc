{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-9288", "model_patch": "diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py\nindex 915d041..7a0d646 100644\n--- a/sklearn/cluster/k_means_.py\n+++ b/sklearn/cluster/k_means_.py\n@@ -378,16 +378,16 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',\n                 best_n_iter = n_iter_\n     else:\n         # parallelisation of k-means runs\n-        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n+        # Use a consistent random state for each job\n         results = Parallel(n_jobs=n_jobs, verbose=0)(\n             delayed(kmeans_single)(X, sample_weight, n_clusters,\n                                    max_iter=max_iter, init=init,\n                                    verbose=verbose, tol=tol,\n                                    precompute_distances=precompute_distances,\n                                    x_squared_norms=x_squared_norms,\n-                                   # Change seed to ensure variety\n-                                   random_state=seed)\n-            for seed in seeds)\n+                                   # Use the same random state for consistency\n+                                   random_state=random_state)\n+            for _ in range(n_init))\n         # Get results with the lowest inertia\n         labels, inertia, centers, n_iters = zip(*results)\n         best = np.argmin(inertia)\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py\nindex abcc315..8058f4f 100644\n--- a/sklearn/cluster/k_means_.py\n+++ b/sklearn/cluster/k_means_.py\n@@ -115,8 +115,7 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++', precompute_dist\n                 best_inertia = inertia\n                 best_n_iter = n_iter_\n     else:\n-        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n-        results = Parallel(n_jobs=n_jobs, verbose=0)((delayed(kmeans_single)(X, sample_weight, n_clusters, max_iter=max_iter, init=init, verbose=verbose, tol=tol, precompute_distances=precompute_distances, x_squared_norms=x_squared_norms, random_state=seed) for seed in seeds))\n+        results = Parallel(n_jobs=n_jobs, verbose=0)((delayed(kmeans_single)(X, sample_weight, n_clusters, max_iter=max_iter, init=init, verbose=verbose, tol=tol, precompute_distances=precompute_distances, x_squared_norms=x_squared_norms, random_state=random_state) for _ in range(n_init)))\n         labels, inertia, centers, n_iters = zip(*results)\n         best = np.argmin(inertia)\n         best_labels = labels[best]\n", "normalized_occurrence": 4}
