{"model_name_or_path": "agentless", "instance_id": "pylint-dev__pylint-4970", "model_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 79a566f..4063600 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -361,7 +361,7 @@ class Similar:\n         ignore_imports: bool = False,\n         ignore_signatures: bool = False,\n     ) -> None:\n-        self.min_lines = min_lines\n+        self.min_lines = min_lines if min_lines > 0 else None\n         self.ignore_comments = ignore_comments\n         self.ignore_docstrings = ignore_docstrings\n         self.ignore_imports = ignore_imports\n@@ -524,14 +524,17 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n-            if eff_cmn_nb > self.min_lines:\n+            if self.min_lines is not None and eff_cmn_nb > self.min_lines:\n                 yield com\n \n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n-        for idx, lineset in enumerate(self.linesets[:-1]):\n+        if self.min_lines is not None:\n+            for idx, lineset in enumerate(self.linesets[:-1]):\n+                for lineset2 in self.linesets[idx + 1 :]:\n+                    yield from self._find_common(lineset, lineset2)\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n \n", "occurrence": 1, "normalized_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 0997b2e..40b8688 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -122,7 +122,7 @@ class Commonality(NamedTuple):\n     snd_file_end: LineNumber\n class Similar:\n     def __init__(self, min_lines: int=DEFAULT_MIN_SIMILARITY_LINE, ignore_comments: bool=False, ignore_docstrings: bool=False, ignore_imports: bool=False, ignore_signatures: bool=False) -> None:\n-        self.min_lines = min_lines\n+        self.min_lines = min_lines if min_lines > 0 else None\n         self.ignore_comments = ignore_comments\n         self.ignore_docstrings = ignore_docstrings\n         self.ignore_imports = ignore_imports\n@@ -207,10 +207,13 @@ class Similar:\n             nb_common_lines = cmn_l.effective_cmn_lines_nb\n             com = Commonality(cmn_lines_nb=nb_common_lines, fst_lset=lineset1, fst_file_start=cmn_l.first_file.start, fst_file_end=cmn_l.first_file.end, snd_lset=lineset2, snd_file_start=cmn_l.second_file.start, snd_file_end=cmn_l.second_file.end)\n             eff_cmn_nb = filter_noncode_lines(lineset1, start_index_1, lineset2, start_index_2, nb_common_lines)\n-            if eff_cmn_nb > self.min_lines:\n+            if self.min_lines is not None and eff_cmn_nb > self.min_lines:\n                 yield com\n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n-        for idx, lineset in enumerate(self.linesets[:-1]):\n+        if self.min_lines is not None:\n+            for idx, lineset in enumerate(self.linesets[:-1]):\n+                for lineset2 in self.linesets[idx + 1:]:\n+                    yield from self._find_common(lineset, lineset2)\n             for lineset2 in self.linesets[idx + 1:]:\n                 yield from self._find_common(lineset, lineset2)\n     def get_map_data(self):\n", "normalized_occurrence": 1}
