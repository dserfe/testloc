{"model_name_or_path": "agentless_claude", "instance_id": "sympy__sympy-24102", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 3e3bc62..d1ccffc 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -615,6 +615,8 @@ class MathematicaParser:\n         tokens.extend(map(re.escape, tokens_escape))\n         tokens.append(\",\")\n         tokens.append(\"\\n\")\n+        # Add pattern for Unicode word characters\n+        tokens.append(r\"[\\w\\u0370-\\u03FF\\u0400-\\u04FF]+\")\n         tokenizer = re.compile(\"(\" + \"|\".join(tokens) + \")\")\n         self._regex_tokenizer = tokenizer\n         return self._regex_tokenizer\n", "occurrence": 1, "normalized_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 957d6fe..7fe3c7f 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -241,6 +241,7 @@ class MathematicaParser:\n         tokens.extend(map(re.escape, tokens_escape))\n         tokens.append(',')\n         tokens.append('\\n')\n+        tokens.append('[\\\\w\\\\u0370-\\\\u03FF\\\\u0400-\\\\u04FF]+')\n         tokenizer = re.compile('(' + '|'.join(tokens) + ')')\n         self._regex_tokenizer = tokenizer\n         return self._regex_tokenizer\n", "normalized_occurrence": 1}
