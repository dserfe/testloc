{"model_name_or_path": "agentless_claude", "instance_id": "scikit-learn__scikit-learn-12682", "model_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex 8cfbe5f..e0bd71c 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -864,12 +864,15 @@ class SparseCodingMixin(TransformerMixin):\n     def _set_sparse_coding_params(self, n_components,\n                                   transform_algorithm='omp',\n                                   transform_n_nonzero_coefs=None,\n-                                  transform_alpha=None, split_sign=False,\n+                                  transform_alpha=None,\n+                                  transform_max_iter=1000,\n+                                  split_sign=False,\n                                   n_jobs=None, positive_code=False):\n         self.n_components = n_components\n         self.transform_algorithm = transform_algorithm\n         self.transform_n_nonzero_coefs = transform_n_nonzero_coefs\n         self.transform_alpha = transform_alpha\n+        self.transform_max_iter = transform_max_iter\n         self.split_sign = split_sign\n         self.n_jobs = n_jobs\n         self.positive_code = positive_code\n@@ -899,8 +902,8 @@ class SparseCodingMixin(TransformerMixin):\n         code = sparse_encode(\n             X, self.components_, algorithm=self.transform_algorithm,\n             n_nonzero_coefs=self.transform_n_nonzero_coefs,\n-            alpha=self.transform_alpha, n_jobs=self.n_jobs,\n-            positive=self.positive_code)\n+            alpha=self.transform_alpha, max_iter=self.transform_max_iter,\n+            n_jobs=self.n_jobs, positive=self.positive_code)\n \n         if self.split_sign:\n             # feature vector is split into a positive and negative side\n@@ -958,6 +961,9 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n         the reconstruction error targeted. In this case, it overrides\n         `n_nonzero_coefs`.\n \n+    transform_max_iter : int, 1000 by default\n+        Maximum number of iterations to perform if `algorithm='lasso_cd'`.\n+\n     split_sign : bool, False by default\n         Whether to split the sparse feature vector into the concatenation of\n         its negative part and its positive part. This can improve the\n@@ -991,11 +997,13 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n \n     def __init__(self, dictionary, transform_algorithm='omp',\n                  transform_n_nonzero_coefs=None, transform_alpha=None,\n-                 split_sign=False, n_jobs=None, positive_code=False):\n+                 transform_max_iter=1000, split_sign=False, n_jobs=None,\n+                 positive_code=False):\n         self._set_sparse_coding_params(dictionary.shape[0],\n                                        transform_algorithm,\n                                        transform_n_nonzero_coefs,\n-                                       transform_alpha, split_sign, n_jobs,\n+                                       transform_alpha, transform_max_iter,\n+                                       split_sign, n_jobs,\n                                        positive_code)\n         self.components_ = dictionary\n \n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex 8a206a7..9976a7f 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -263,18 +263,19 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100, return_code=Tru\n     else:\n         return dictionary.T\n class SparseCodingMixin(TransformerMixin):\n-    def _set_sparse_coding_params(self, n_components, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, split_sign=False, n_jobs=None, positive_code=False):\n+    def _set_sparse_coding_params(self, n_components, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, transform_max_iter=1000, split_sign=False, n_jobs=None, positive_code=False):\n         self.n_components = n_components\n         self.transform_algorithm = transform_algorithm\n         self.transform_n_nonzero_coefs = transform_n_nonzero_coefs\n         self.transform_alpha = transform_alpha\n+        self.transform_max_iter = transform_max_iter\n         self.split_sign = split_sign\n         self.n_jobs = n_jobs\n         self.positive_code = positive_code\n     def transform(self, X):\n         check_is_fitted(self, 'components_')\n         X = check_array(X)\n-        code = sparse_encode(X, self.components_, algorithm=self.transform_algorithm, n_nonzero_coefs=self.transform_n_nonzero_coefs, alpha=self.transform_alpha, n_jobs=self.n_jobs, positive=self.positive_code)\n+        code = sparse_encode(X, self.components_, algorithm=self.transform_algorithm, n_nonzero_coefs=self.transform_n_nonzero_coefs, alpha=self.transform_alpha, max_iter=self.transform_max_iter, n_jobs=self.n_jobs, positive=self.positive_code)\n         if self.split_sign:\n             n_samples, n_features = code.shape\n             split_code = np.empty((n_samples, 2 * n_features))\n@@ -284,8 +285,8 @@ class SparseCodingMixin(TransformerMixin):\n         return code\n class SparseCoder(BaseEstimator, SparseCodingMixin):\n     _required_parameters = ['dictionary']\n-    def __init__(self, dictionary, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, split_sign=False, n_jobs=None, positive_code=False):\n-        self._set_sparse_coding_params(dictionary.shape[0], transform_algorithm, transform_n_nonzero_coefs, transform_alpha, split_sign, n_jobs, positive_code)\n+    def __init__(self, dictionary, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, transform_max_iter=1000, split_sign=False, n_jobs=None, positive_code=False):\n+        self._set_sparse_coding_params(dictionary.shape[0], transform_algorithm, transform_n_nonzero_coefs, transform_alpha, transform_max_iter, split_sign, n_jobs, positive_code)\n         self.components_ = dictionary\n     def fit(self, X, y=None):\n         return self\n", "normalized_occurrence": 1}
