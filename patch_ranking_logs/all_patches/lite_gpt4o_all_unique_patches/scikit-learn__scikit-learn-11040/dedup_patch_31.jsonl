{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-11040", "model_patch": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 01d85d0..cefdc19 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -107,7 +107,7 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n                  p=2, metric_params=None, n_jobs=1):\n \n-        self.n_neighbors = n_neighbors\n+        self.n_neighbors = self._validate_n_neighbors(n_neighbors)\n         self.radius = radius\n         self.algorithm = algorithm\n         self.leaf_size = leaf_size\n@@ -253,10 +253,10 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n                              % self.algorithm)\n \n         if self.n_neighbors is not None:\n-            if self.n_neighbors <= 0:\n+            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n                 raise ValueError(\n-                    \"Expected n_neighbors > 0. Got %d\" %\n-                    self.n_neighbors\n+                    \"Expected n_neighbors > 0. Got %s\" %\n+                    str(self.n_neighbors)\n                 )\n \n         return self\n@@ -271,6 +271,8 @@ class KNeighborsMixin(object):\n     \"\"\"Mixin for k-neighbors searches\"\"\"\n \n     def kneighbors(self, X=None, n_neighbors=None, return_distance=True):\n+        if n_neighbors is not None:\n+            n_neighbors = self._validate_n_neighbors(n_neighbors)\n         \"\"\"Finds the K-neighbors of a point.\n \n         Returns indices of and distances to the neighbors of each point.\n@@ -325,7 +327,10 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n-        if n_neighbors is None:\n+        def _validate_n_neighbors(self, n_neighbors):\n+            if not isinstance(n_neighbors, int) or n_neighbors <= 0:\n+                raise ValueError(\"Expected n_neighbors to be a positive integer. Got %s\" % str(n_neighbors))\n+            return n_neighbors\n             n_neighbors = self.n_neighbors\n \n         if X is not None:\n@@ -464,7 +469,10 @@ class KNeighborsMixin(object):\n         --------\n         NearestNeighbors.radius_neighbors_graph\n         \"\"\"\n-        if n_neighbors is None:\n+        def _validate_n_neighbors(self, n_neighbors):\n+            if not isinstance(n_neighbors, int) or n_neighbors <= 0:\n+                raise ValueError(\"Expected n_neighbors to be a positive integer. Got %s\" % str(n_neighbors))\n+            return n_neighbors\n             n_neighbors = self.n_neighbors\n \n         # kneighbors does the None handling.\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex ddfefae..5e75ad9 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -47,7 +47,7 @@ def _get_weights(dist, weights):\n class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     @abstractmethod\n     def __init__(self, n_neighbors=None, radius=None, algorithm='auto', leaf_size=30, metric='minkowski', p=2, metric_params=None, n_jobs=1):\n-        self.n_neighbors = n_neighbors\n+        self.n_neighbors = self._validate_n_neighbors(n_neighbors)\n         self.radius = radius\n         self.algorithm = algorithm\n         self.leaf_size = leaf_size\n@@ -151,16 +151,22 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         else:\n             raise ValueError(\"algorithm = '%s' not recognized\" % self.algorithm)\n         if self.n_neighbors is not None:\n-            if self.n_neighbors <= 0:\n-                raise ValueError('Expected n_neighbors > 0. Got %d' % self.n_neighbors)\n+            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n+                raise ValueError('Expected n_neighbors > 0. Got %s' % str(self.n_neighbors))\n         return self\n     @property\n     def _pairwise(self):\n         return self.metric == 'precomputed'\n class KNeighborsMixin(object):\n     def kneighbors(self, X=None, n_neighbors=None, return_distance=True):\n+        if n_neighbors is not None:\n+            n_neighbors = self._validate_n_neighbors(n_neighbors)\n+        \"Finds the K-neighbors of a point.\\n\\n        Returns indices of and distances to the neighbors of each point.\\n\\n        Parameters\\n        ----------\\n        X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\\n            The query point or points.\\n            If not provided, neighbors of each indexed point are returned.\\n            In this case, the query point is not considered its own neighbor.\\n\\n        n_neighbors : int\\n            Number of neighbors to get (default is the value\\n            passed to the constructor).\\n\\n        return_distance : boolean, optional. Defaults to True.\\n            If False, distances will not be returned\\n\\n        Returns\\n        -------\\n        dist : array\\n            Array representing the lengths to points, only present if\\n            return_distance=True\\n\\n        ind : array\\n            Indices of the nearest points in the population matrix.\\n\\n        Examples\\n        --------\\n        In the following example, we construct a NeighborsClassifier\\n        class from an array representing our data set and ask who's\\n        the closest point to [1,1,1]\\n\\n        >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\\n        >>> from sklearn.neighbors import NearestNeighbors\\n        >>> neigh = NearestNeighbors(n_neighbors=1)\\n        >>> neigh.fit(samples) # doctest: +ELLIPSIS\\n        NearestNeighbors(algorithm='auto', leaf_size=30, ...)\\n        >>> print(neigh.kneighbors([[1., 1., 1.]])) # doctest: +ELLIPSIS\\n        (array([[0.5]]), array([[2]]))\\n\\n        As you can see, it returns [[0.5]], and [[2]], which means that the\\n        element is at distance 0.5 and is the third element of samples\\n        (indexes start at 0). You can also query for multiple points:\\n\\n        >>> X = [[0., 1., 0.], [1., 0., 1.]]\\n        >>> neigh.kneighbors(X, return_distance=False) # doctest: +ELLIPSIS\\n        array([[1],\\n               [2]]...)\\n\\n        \"\n         check_is_fitted(self, '_fit_method')\n-        if n_neighbors is None:\n+        def _validate_n_neighbors(self, n_neighbors):\n+            if not isinstance(n_neighbors, int) or n_neighbors <= 0:\n+                raise ValueError('Expected n_neighbors to be a positive integer. Got %s' % str(n_neighbors))\n+            return n_neighbors\n             n_neighbors = self.n_neighbors\n         if X is not None:\n             query_is_train = False\n@@ -217,7 +223,10 @@ class KNeighborsMixin(object):\n                 return (dist, neigh_ind)\n             return neigh_ind\n     def kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity'):\n-        if n_neighbors is None:\n+        def _validate_n_neighbors(self, n_neighbors):\n+            if not isinstance(n_neighbors, int) or n_neighbors <= 0:\n+                raise ValueError('Expected n_neighbors to be a positive integer. Got %s' % str(n_neighbors))\n+            return n_neighbors\n             n_neighbors = self.n_neighbors\n         if X is not None:\n             X = check_array(X, accept_sparse='csr')\n", "normalized_occurrence": 1}
