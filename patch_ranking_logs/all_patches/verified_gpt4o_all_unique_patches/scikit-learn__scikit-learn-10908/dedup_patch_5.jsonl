{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-10908", "model_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex 7e240fc..11de107 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -301,7 +301,11 @@ class VectorizerMixin(object):\n     def _check_vocabulary(self):\n         \"\"\"Check if vocabulary is empty or missing (not fit-ed)\"\"\"\n         msg = \"%(name)s - Vocabulary wasn't fitted.\"\n-        check_is_fitted(self, 'vocabulary_', msg=msg),\n+        if not hasattr(self, 'vocabulary_'):\n+            if self.fixed_vocabulary_:\n+                self._validate_vocabulary()\n+            else:\n+                check_is_fitted(self, 'vocabulary_', msg=msg)\n \n         if len(self.vocabulary_) == 0:\n             raise ValueError(\"Vocabulary is empty\")\n@@ -953,7 +957,11 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n         if not hasattr(self, 'vocabulary_'):\n             self._validate_vocabulary()\n \n-        self._check_vocabulary()\n+        if not hasattr(self, 'vocabulary_'):\n+            if self.fixed_vocabulary_:\n+                self._validate_vocabulary()\n+            else:\n+                raise NotFittedError(\"Vocabulary wasn't fitted.\")\n \n         # use the same matrix-building strategy as fit_transform\n         _, X = self._count_vocab(raw_documents, fixed_vocab=True)\n@@ -993,7 +1001,11 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n \n     def get_feature_names(self):\n         \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n-        self._check_vocabulary()\n+        if not hasattr(self, 'vocabulary_'):\n+            if self.fixed_vocabulary_:\n+                self._validate_vocabulary()\n+            else:\n+                raise NotFittedError(\"Vocabulary wasn't fitted.\")\n \n         return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n                                      key=itemgetter(1))]\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex 583049b..0af231f 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -165,7 +165,11 @@ class VectorizerMixin(object):\n             self.fixed_vocabulary_ = False\n     def _check_vocabulary(self):\n         msg = \"%(name)s - Vocabulary wasn't fitted.\"\n-        (check_is_fitted(self, 'vocabulary_', msg=msg),)\n+        if not hasattr(self, 'vocabulary_'):\n+            if self.fixed_vocabulary_:\n+                self._validate_vocabulary()\n+            else:\n+                check_is_fitted(self, 'vocabulary_', msg=msg)\n         if len(self.vocabulary_) == 0:\n             raise ValueError('Vocabulary is empty')\n     def _validate_params(self):\n@@ -347,7 +351,11 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n             raise ValueError('Iterable over raw text documents expected, string object received.')\n         if not hasattr(self, 'vocabulary_'):\n             self._validate_vocabulary()\n-        self._check_vocabulary()\n+        if not hasattr(self, 'vocabulary_'):\n+            if self.fixed_vocabulary_:\n+                self._validate_vocabulary()\n+            else:\n+                raise NotFittedError(\"Vocabulary wasn't fitted.\")\n         _, X = self._count_vocab(raw_documents, fixed_vocab=True)\n         if self.binary:\n             X.data.fill(1)\n@@ -364,7 +372,11 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n         inverse_vocabulary = terms[np.argsort(indices)]\n         return [inverse_vocabulary[X[i, :].nonzero()[1]].ravel() for i in range(n_samples)]\n     def get_feature_names(self):\n-        self._check_vocabulary()\n+        if not hasattr(self, 'vocabulary_'):\n+            if self.fixed_vocabulary_:\n+                self._validate_vocabulary()\n+            else:\n+                raise NotFittedError(\"Vocabulary wasn't fitted.\")\n         return [t for t, i in sorted(six.iteritems(self.vocabulary_), key=itemgetter(1))]\n def _make_int_array():\n     return array.array(str('i'))\n", "normalized_occurrence": 1}
