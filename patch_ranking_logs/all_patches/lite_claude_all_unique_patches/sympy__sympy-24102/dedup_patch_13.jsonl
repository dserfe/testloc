{"model_name_or_path": "agentless_claude", "instance_id": "sympy__sympy-24102", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 3e3bc62..77077b6 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -615,7 +615,9 @@ class MathematicaParser:\n         tokens.extend(map(re.escape, tokens_escape))\n         tokens.append(\",\")\n         tokens.append(\"\\n\")\n-        tokenizer = re.compile(\"(\" + \"|\".join(tokens) + \")\")\n+        # Add support for Unicode characters\n+        tokens.append(r\"\\w+\")  # This will match Unicode word characters\n+        tokenizer = re.compile(\"(\" + \"|\".join(tokens) + \")\", re.UNICODE)\n         self._regex_tokenizer = tokenizer\n         return self._regex_tokenizer\n \n", "occurrence": 1, "normalized_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 957d6fe..ef54ac7 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -241,7 +241,8 @@ class MathematicaParser:\n         tokens.extend(map(re.escape, tokens_escape))\n         tokens.append(',')\n         tokens.append('\\n')\n-        tokenizer = re.compile('(' + '|'.join(tokens) + ')')\n+        tokens.append('\\\\w+')\n+        tokenizer = re.compile('(' + '|'.join(tokens) + ')', re.UNICODE)\n         self._regex_tokenizer = tokenizer\n         return self._regex_tokenizer\n     def _from_mathematica_to_tokens(self, code: str):\n", "normalized_occurrence": 3}
