{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13496", "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 17608bc..356afab 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -133,6 +133,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n     max_samples_ : integer\n         The actual number of samples\n \n+    warm_start : bool\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+        \n     offset_ : float\n         Offset used to define the decision function from the raw scores.\n         We have the relation: ``decision_function = score_samples - offset_``.\n@@ -173,7 +178,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n+                 verbose=0,\n+                 warm_start=False):\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n@@ -187,11 +193,14 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             max_features=max_features,\n             n_jobs=n_jobs,\n             random_state=random_state,\n-            verbose=verbose)\n+            verbose=verbose,\n+            warm_start=warm_start)\n \n         self.behaviour = behaviour\n         self.contamination = contamination\n \n+        self.warm_start = warm_start\n+\n     def _set_oob_score(self, X, y):\n         raise NotImplementedError(\"OOB score not supported by iforest\")\n \n@@ -305,6 +314,12 @@ class IsolationForest(BaseBagging, OutlierMixin):\n \n         return self\n \n+    def fit(self, X, y=None, sample_weight=None):\n+        # Increment n_estimators if warm_start is enabled and already fitted\n+        if self.warm_start and hasattr(self, \"estimators_\"):\n+            self.n_estimators += len(self.estimators_)\n+        return super().fit(X, y, sample_weight)\n+\n     def predict(self, X):\n         \"\"\"Predict if a particular sample is an outlier or not.\n \n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 3ca6fb5..6a1f139 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -11,10 +11,11 @@ from .bagging import BaseBagging\n __all__ = ['IsolationForest']\n INTEGER_TYPES = (numbers.Integral, np.integer)\n class IsolationForest(BaseBagging, OutlierMixin):\n-    def __init__(self, n_estimators=100, max_samples='auto', contamination='legacy', max_features=1.0, bootstrap=False, n_jobs=None, behaviour='old', random_state=None, verbose=0):\n-        super().__init__(base_estimator=ExtraTreeRegressor(max_features=1, splitter='random', random_state=random_state), bootstrap=bootstrap, bootstrap_features=False, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, n_jobs=n_jobs, random_state=random_state, verbose=verbose)\n+    def __init__(self, n_estimators=100, max_samples='auto', contamination='legacy', max_features=1.0, bootstrap=False, n_jobs=None, behaviour='old', random_state=None, verbose=0, warm_start=False):\n+        super().__init__(base_estimator=ExtraTreeRegressor(max_features=1, splitter='random', random_state=random_state), bootstrap=bootstrap, bootstrap_features=False, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, n_jobs=n_jobs, random_state=random_state, verbose=verbose, warm_start=warm_start)\n         self.behaviour = behaviour\n         self.contamination = contamination\n+        self.warm_start = warm_start\n     def _set_oob_score(self, X, y):\n         raise NotImplementedError('OOB score not supported by iforest')\n     def _parallel_args(self):\n@@ -62,6 +63,10 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             return self\n         self.offset_ = np.percentile(self.score_samples(X), 100.0 * self._contamination)\n         return self\n+    def fit(self, X, y=None, sample_weight=None):\n+        if self.warm_start and hasattr(self, 'estimators_'):\n+            self.n_estimators += len(self.estimators_)\n+        return super().fit(X, y, sample_weight)\n     def predict(self, X):\n         check_is_fitted(self, ['offset_'])\n         X = check_array(X, accept_sparse='csr')\n", "normalized_occurrence": 1}
