{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-4094", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 1e17b93..d25ad54 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3452,21 +3452,31 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n                 )\n \n         def ensure_stackable(val):\n-            assign_coords = {variable_dim: val.name}\n-            for dim in stacking_dims:\n-                if dim not in val.dims:\n-                    assign_coords[dim] = None\n-\n-            expand_dims = set(stacking_dims).difference(set(val.dims))\n-            expand_dims.add(variable_dim)\n-            # must be list for .expand_dims\n-            expand_dims = list(expand_dims)\n-\n-            return (\n-                val.assign_coords(**assign_coords)\n-                .expand_dims(expand_dims)\n-                .stack({new_dim: (variable_dim,) + stacking_dims})\n-            )\n+            if len(stacking_dims) == 0:\n+                # If there are no stacking_dims, we only need to handle the variable_dim\n+                assign_coords = {variable_dim: val.name}\n+                expand_dims = [variable_dim]\n+                return (\n+                    val.assign_coords(**assign_coords)\n+                    .expand_dims(expand_dims)\n+                    .stack({new_dim: (variable_dim,)})\n+                )\n+            else:\n+                assign_coords = {variable_dim: val.name}\n+                for dim in stacking_dims:\n+                    if dim not in val.dims:\n+                        assign_coords[dim] = None\n+\n+                expand_dims = set(stacking_dims).difference(set(val.dims))\n+                expand_dims.add(variable_dim)\n+                # must be list for .expand_dims\n+                expand_dims = list(expand_dims)\n+\n+                return (\n+                    val.assign_coords(**assign_coords)\n+                    .expand_dims(expand_dims)\n+                    .stack({new_dim: (variable_dim,) + stacking_dims})\n+                )\n \n         # concatenate the arrays\n         stackable_vars = [ensure_stackable(self[key]) for key in self.data_vars]\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 21ef2a4..38884fc 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1146,14 +1146,19 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n             if not dims_include_sample_dims:\n                 raise ValueError('All variables in the dataset must contain the dimensions {}.'.format(dims))\n         def ensure_stackable(val):\n-            assign_coords = {variable_dim: val.name}\n-            for dim in stacking_dims:\n-                if dim not in val.dims:\n-                    assign_coords[dim] = None\n-            expand_dims = set(stacking_dims).difference(set(val.dims))\n-            expand_dims.add(variable_dim)\n-            expand_dims = list(expand_dims)\n-            return val.assign_coords(**assign_coords).expand_dims(expand_dims).stack({new_dim: (variable_dim,) + stacking_dims})\n+            if len(stacking_dims) == 0:\n+                assign_coords = {variable_dim: val.name}\n+                expand_dims = [variable_dim]\n+                return val.assign_coords(**assign_coords).expand_dims(expand_dims).stack({new_dim: (variable_dim,)})\n+            else:\n+                assign_coords = {variable_dim: val.name}\n+                for dim in stacking_dims:\n+                    if dim not in val.dims:\n+                        assign_coords[dim] = None\n+                expand_dims = set(stacking_dims).difference(set(val.dims))\n+                expand_dims.add(variable_dim)\n+                expand_dims = list(expand_dims)\n+                return val.assign_coords(**assign_coords).expand_dims(expand_dims).stack({new_dim: (variable_dim,) + stacking_dims})\n         stackable_vars = [ensure_stackable(self[key]) for key in self.data_vars]\n         data_array = xr.concat(stackable_vars, dim=new_dim)\n         idx = data_array.indexes[new_dim]\n", "normalized_occurrence": 1}
