{"model_name_or_path": "agentless_claude", "instance_id": "matplotlib__matplotlib-20488", "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex bbcae54..f5d4d0d 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1551,6 +1551,33 @@ class LogNorm(Normalize):\n         # docstring inherited.\n         super().autoscale_None(np.ma.masked_less_equal(A, 0, copy=False))\n \n+    def __call__(self, value, clip=None):\n+        \"\"\"\n+        Normalize *value* data in the ``[vmin, vmax]`` interval into the\n+        ``[0.0, 1.0]`` interval and return it.\n+        \"\"\"\n+        value, is_scalar = self.process_value(value)\n+        self.autoscale_None(value)\n+        if self.vmin > self.vmax:\n+            raise ValueError(\"vmin must be less or equal to vmax\")\n+        if self.vmin <= 0:\n+            raise ValueError(\"vmin must be positive for LogNorm\")\n+        if self.vmax <= 0:\n+            raise ValueError(\"vmax must be positive for LogNorm\")\n+        if self.vmin == self.vmax:\n+            return np.full_like(value, 0)\n+        if clip is None:\n+            clip = self.clip\n+        if clip:\n+            value = np.clip(value, self.vmin, self.vmax)\n+        t_value = self._trf.transform(value).reshape(np.shape(value))\n+        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n+        if not np.isfinite([t_vmin, t_vmax]).all():\n+            # Handle extreme values by falling back to simpler normalization\n+            log_vmin, log_vmax = np.log10(self.vmin), np.log10(self.vmax)\n+            log_val = np.log10(value)\n+            return (log_val - log_vmin) / (log_vmax - log_vmin)\n+\n \n @_make_norm_from_scale(\n     scale.SymmetricalLogScale,\n", "normalized_patch": "--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n+    def __call__(self, value, clip=None):\n+        \"\"\"\n+        Normalize *value* data in the ``[vmin, vmax]`` interval into the\n+        ``[0.0, 1.0]`` interval and return it.\n+        \"\"\"\n+        value, is_scalar = self.process_value(value)\n+        self.autoscale_None(value)\n+        if self.vmin > self.vmax:\n+            raise ValueError('vmin must be less or equal to vmax')\n+        if self.vmin <= 0:\n+            raise ValueError('vmin must be positive for LogNorm')\n+        if self.vmax <= 0:\n+            raise ValueError('vmax must be positive for LogNorm')\n+        if self.vmin == self.vmax:\n+            return np.full_like(value, 0)\n+        if clip is None:\n+            clip = self.clip\n+        if clip:\n+            value = np.clip(value, self.vmin, self.vmax)\n+        t_value = self._trf.transform(value).reshape(np.shape(value))\n+        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n+        if not np.isfinite([t_vmin, t_vmax]).all():\n+            log_vmin, log_vmax = (np.log10(self.vmin), np.log10(self.vmax))\n+            log_val = np.log10(value)\n+            return (log_val - log_vmin) / (log_vmax - log_vmin)\n+", "normalized_occurrence": 1}
