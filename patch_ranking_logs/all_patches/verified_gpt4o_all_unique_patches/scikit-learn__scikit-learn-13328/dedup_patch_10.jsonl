{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13328", "model_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 774a22b..50531af 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -25,7 +25,7 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n         gives the intercept factor.\n \n     X : ndarray, shape (n_samples, n_features)\n-        Input data.\n+        Input data. This will be converted to float if it is boolean.\n \n     y : ndarray, shape (n_samples,)\n         Target vector.\n@@ -48,6 +48,9 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n         Returns the derivative of the Huber loss with respect to each\n         coefficient, intercept and the scale as a vector.\n     \"\"\"\n+    # Convert boolean data to float\n+    if X.dtype == np.bool_:\n+        X = X.astype(np.float64)\n     _, n_features = X.shape\n     fit_intercept = (n_features + 2 == w.shape[0])\n     if fit_intercept:\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 81acf45..9650e8b 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -7,6 +7,8 @@ from ..utils import check_consistent_length\n from ..utils import axis0_safe_slice\n from ..utils.extmath import safe_sparse_dot\n def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n+    if X.dtype == np.bool_:\n+        X = X.astype(np.float64)\n     _, n_features = X.shape\n     fit_intercept = n_features + 2 == w.shape[0]\n     if fit_intercept:\n", "normalized_occurrence": 1}
