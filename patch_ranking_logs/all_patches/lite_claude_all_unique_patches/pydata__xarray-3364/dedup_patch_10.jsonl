{"model_name_or_path": "agentless_claude", "instance_id": "pydata__xarray-3364", "model_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex 1ac1b8e..77c70ad 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -1,4 +1,7 @@\n+\n import pandas as pd\n+import numpy as np\n+from numpy import full_like\n \n from . import dtypes, utils\n from .alignment import align\n@@ -358,10 +361,18 @@ def _dataset_concat(\n     # n.b. this loop preserves variable order, needed for groupby.\n     for k in datasets[0].variables:\n         if k in concat_over:\n-            try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n-                raise ValueError(\"%r is not present in all datasets.\" % k)\n+            # Handle missing variables by creating them with fill_value\n+            vars = []\n+            for ds in datasets:\n+                if k in ds.variables:\n+                    vars.append(ds.variables[k])\n+                else:\n+                    # Create a new variable filled with fill_value matching the first dataset's shape\n+                    first_var = next(ds for ds in datasets if k in ds.variables).variables[k]\n+                    new_var = Variable(first_var.dims, None, first_var.attrs)\n+                    new_var.values = full_like(first_var, fill_value)\n+                    vars.append(new_var)\n+            vars = list(ensure_common_dims(vars))\n             combined = concat_vars(vars, dim, positions)\n             assert isinstance(combined, Variable)\n             result_vars[k] = combined\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex 06e5a50..4fd9bc7 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -1,4 +1,6 @@\n import pandas as pd\n+import numpy as np\n+from numpy import full_like\n from . import dtypes, utils\n from .alignment import align\n from .merge import _VALID_COMPAT, unique_variable\n@@ -152,10 +154,16 @@ def _dataset_concat(datasets, dim, data_vars, coords, compat, positions, fill_va\n             yield var\n     for k in datasets[0].variables:\n         if k in concat_over:\n-            try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n-                raise ValueError('%r is not present in all datasets.' % k)\n+            vars = []\n+            for ds in datasets:\n+                if k in ds.variables:\n+                    vars.append(ds.variables[k])\n+                else:\n+                    first_var = next((ds for ds in datasets if k in ds.variables)).variables[k]\n+                    new_var = Variable(first_var.dims, None, first_var.attrs)\n+                    new_var.values = full_like(first_var, fill_value)\n+                    vars.append(new_var)\n+            vars = list(ensure_common_dims(vars))\n             combined = concat_vars(vars, dim, positions)\n             assert isinstance(combined, Variable)\n             result_vars[k] = combined\n", "normalized_occurrence": 1}
