{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13496", "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 17608bc..69bdaeb 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -85,6 +85,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n         data sampled with replacement. If False, sampling without replacement\n         is performed.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n     n_jobs : int or None, optional (default=None)\n         The number of jobs to run in parallel for both `fit` and `predict`.\n         ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n@@ -173,6 +178,7 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n+                 warm_start=False,\n                  verbose=0):\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n@@ -187,8 +193,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             max_features=max_features,\n             n_jobs=n_jobs,\n             random_state=random_state,\n+            warm_start=warm_start,\n             verbose=verbose)\n \n+        self.warm_start = warm_start\n+\n         self.behaviour = behaviour\n         self.contamination = contamination\n \n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 3ca6fb5..3c3aac0 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -11,8 +11,9 @@ from .bagging import BaseBagging\n __all__ = ['IsolationForest']\n INTEGER_TYPES = (numbers.Integral, np.integer)\n class IsolationForest(BaseBagging, OutlierMixin):\n-    def __init__(self, n_estimators=100, max_samples='auto', contamination='legacy', max_features=1.0, bootstrap=False, n_jobs=None, behaviour='old', random_state=None, verbose=0):\n-        super().__init__(base_estimator=ExtraTreeRegressor(max_features=1, splitter='random', random_state=random_state), bootstrap=bootstrap, bootstrap_features=False, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, n_jobs=n_jobs, random_state=random_state, verbose=verbose)\n+    def __init__(self, n_estimators=100, max_samples='auto', contamination='legacy', max_features=1.0, bootstrap=False, n_jobs=None, behaviour='old', random_state=None, warm_start=False, verbose=0):\n+        super().__init__(base_estimator=ExtraTreeRegressor(max_features=1, splitter='random', random_state=random_state), bootstrap=bootstrap, bootstrap_features=False, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, n_jobs=n_jobs, random_state=random_state, warm_start=warm_start, verbose=verbose)\n+        self.warm_start = warm_start\n         self.behaviour = behaviour\n         self.contamination = contamination\n     def _set_oob_score(self, X, y):\n", "normalized_occurrence": 1}
