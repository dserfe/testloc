{"model_name_or_path": "agentless_claude", "instance_id": "scikit-learn__scikit-learn-12973", "model_patch": "diff --git a/sklearn/linear_model/least_angle.py b/sklearn/linear_model/least_angle.py\nindex b1d16f1..0dec697 100644\n--- a/sklearn/linear_model/least_angle.py\n+++ b/sklearn/linear_model/least_angle.py\n@@ -1479,7 +1479,7 @@ class LassoLarsIC(LassoLars):\n         self.eps = eps\n         self.fit_path = True\n \n-    def fit(self, X, y, copy_X=True):\n+    def fit(self, X, y, copy_X=None):\n         \"\"\"Fit the model using X, y as training data.\n \n         Parameters\n@@ -1490,8 +1490,9 @@ class LassoLarsIC(LassoLars):\n         y : array-like, shape (n_samples,)\n             target values. Will be cast to X's dtype if necessary\n \n-        copy_X : boolean, optional, default True\n+        copy_X : boolean, optional, default None\n             If ``True``, X will be copied; else, it may be overwritten.\n+            If None, defaults to the value passed in the constructor.\n \n         Returns\n         -------\n@@ -1500,14 +1501,15 @@ class LassoLarsIC(LassoLars):\n         \"\"\"\n         X, y = check_X_y(X, y, y_numeric=True)\n \n+        copy_X_value = self.copy_X if copy_X is None else copy_X\n         X, y, Xmean, ymean, Xstd = LinearModel._preprocess_data(\n-            X, y, self.fit_intercept, self.normalize, self.copy_X)\n+            X, y, self.fit_intercept, self.normalize, copy_X_value)\n         max_iter = self.max_iter\n \n         Gram = self.precompute\n \n         alphas_, active_, coef_path_, self.n_iter_ = lars_path(\n-            X, y, Gram=Gram, copy_X=copy_X, copy_Gram=True, alpha_min=0.0,\n+            X, y, Gram=Gram, copy_X=copy_X_value, copy_Gram=True, alpha_min=0.0,\n             method='lasso', verbose=self.verbose, max_iter=max_iter,\n             eps=self.eps, return_n_iter=True, positive=self.positive)\n \n@@ -1543,4 +1545,4 @@ class LassoLarsIC(LassoLars):\n         self.alpha_ = alphas_[n_best]\n         self.coef_ = coef_path_[:, n_best]\n         self._set_intercept(Xmean, ymean, Xstd)\n-        return self\n+        return self\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/linear_model/least_angle.py b/sklearn/linear_model/least_angle.py\nindex 04326da..3ddc3f6 100644\n--- a/sklearn/linear_model/least_angle.py\n+++ b/sklearn/linear_model/least_angle.py\n@@ -383,12 +383,13 @@ class LassoLarsIC(LassoLars):\n         self.precompute = precompute\n         self.eps = eps\n         self.fit_path = True\n-    def fit(self, X, y, copy_X=True):\n+    def fit(self, X, y, copy_X=None):\n         X, y = check_X_y(X, y, y_numeric=True)\n-        X, y, Xmean, ymean, Xstd = LinearModel._preprocess_data(X, y, self.fit_intercept, self.normalize, self.copy_X)\n+        copy_X_value = self.copy_X if copy_X is None else copy_X\n+        X, y, Xmean, ymean, Xstd = LinearModel._preprocess_data(X, y, self.fit_intercept, self.normalize, copy_X_value)\n         max_iter = self.max_iter\n         Gram = self.precompute\n-        alphas_, active_, coef_path_, self.n_iter_ = lars_path(X, y, Gram=Gram, copy_X=copy_X, copy_Gram=True, alpha_min=0.0, method='lasso', verbose=self.verbose, max_iter=max_iter, eps=self.eps, return_n_iter=True, positive=self.positive)\n+        alphas_, active_, coef_path_, self.n_iter_ = lars_path(X, y, Gram=Gram, copy_X=copy_X_value, copy_Gram=True, alpha_min=0.0, method='lasso', verbose=self.verbose, max_iter=max_iter, eps=self.eps, return_n_iter=True, positive=self.positive)\n         n_samples = X.shape[0]\n         if self.criterion == 'aic':\n             K = 2\n", "normalized_occurrence": 1}
