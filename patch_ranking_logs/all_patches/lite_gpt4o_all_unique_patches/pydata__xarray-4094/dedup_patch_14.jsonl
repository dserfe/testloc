{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-4094", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 1e17b93..c1ddf56 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3454,10 +3454,10 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         def ensure_stackable(val):\n             assign_coords = {variable_dim: val.name}\n             for dim in stacking_dims:\n-                if dim not in val.dims:\n-                    assign_coords[dim] = None\n+                if dim not in val.dims and dim in stacking_dims:\n+                    assign_coords[dim] = np.nan\n \n-            expand_dims = set(stacking_dims).difference(set(val.dims))\n+            expand_dims = set(stacking_dims).difference(set(val.dims) & set(stacking_dims))\n             expand_dims.add(variable_dim)\n             # must be list for .expand_dims\n             expand_dims = list(expand_dims)\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 21ef2a4..0bc50a5 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1148,9 +1148,9 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         def ensure_stackable(val):\n             assign_coords = {variable_dim: val.name}\n             for dim in stacking_dims:\n-                if dim not in val.dims:\n-                    assign_coords[dim] = None\n-            expand_dims = set(stacking_dims).difference(set(val.dims))\n+                if dim not in val.dims and dim in stacking_dims:\n+                    assign_coords[dim] = np.nan\n+            expand_dims = set(stacking_dims).difference(set(val.dims) & set(stacking_dims))\n             expand_dims.add(variable_dim)\n             expand_dims = list(expand_dims)\n             return val.assign_coords(**assign_coords).expand_dims(expand_dims).stack({new_dim: (variable_dim,) + stacking_dims})\n", "normalized_occurrence": 1}
