{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-25931", "model_patch": "diff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex d995c25..705c562 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -289,6 +289,7 @@ class IsolationForest(OutlierMixin, BaseBagging):\n         \"\"\"\n         self._validate_params()\n         X = self._validate_data(X, accept_sparse=[\"csc\"], dtype=tree_dtype)\n+        self.feature_names_in_ = _get_feature_names(X)\n         if issparse(X):\n             # Pre-sort indices to avoid that each individual tree of the\n             # ensemble sorts the indices.\n@@ -433,7 +434,9 @@ class IsolationForest(OutlierMixin, BaseBagging):\n         check_is_fitted(self)\n \n         # Check data\n-        X = self._validate_data(X, accept_sparse=\"csr\", dtype=np.float32, reset=False)\n+        X = self._validate_data(X, accept_sparse=\"csr\", dtype=np.float32, reset=False, ensure_2d=True)\n+        if hasattr(self, 'feature_names_in_'):\n+            self._check_feature_names(X, reset=False)\n \n         # Take the opposite of the scores as bigger is better (here less\n         # abnormal)\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex f9e64b9..ada0972 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -24,6 +24,7 @@ class IsolationForest(OutlierMixin, BaseBagging):\n     def fit(self, X, y=None, sample_weight=None):\n         self._validate_params()\n         X = self._validate_data(X, accept_sparse=['csc'], dtype=tree_dtype)\n+        self.feature_names_in_ = _get_feature_names(X)\n         if issparse(X):\n             X.sort_indices()\n         rnd = check_random_state(self.random_state)\n@@ -58,7 +59,9 @@ class IsolationForest(OutlierMixin, BaseBagging):\n         return self.score_samples(X) - self.offset_\n     def score_samples(self, X):\n         check_is_fitted(self)\n-        X = self._validate_data(X, accept_sparse='csr', dtype=np.float32, reset=False)\n+        X = self._validate_data(X, accept_sparse='csr', dtype=np.float32, reset=False, ensure_2d=True)\n+        if hasattr(self, 'feature_names_in_'):\n+            self._check_feature_names(X, reset=False)\n         return -self._compute_chunked_score_samples(X)\n     def _compute_chunked_score_samples(self, X):\n         n_samples = _num_samples(X)\n", "normalized_occurrence": 1}
