{"model_name_or_path": "agentless_claude", "instance_id": "sympy__sympy-24102", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 3e3bc62..fc807b5 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -615,7 +615,8 @@ class MathematicaParser:\n         tokens.extend(map(re.escape, tokens_escape))\n         tokens.append(\",\")\n         tokens.append(\"\\n\")\n-        tokenizer = re.compile(\"(\" + \"|\".join(tokens) + \")\")\n+        # Add support for Unicode characters by using re.UNICODE flag\n+        tokenizer = re.compile(\"(\" + \"|\".join(tokens) + \")\", re.UNICODE)\n         self._regex_tokenizer = tokenizer\n         return self._regex_tokenizer\n \n", "occurrence": 1, "normalized_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 957d6fe..ec8d956 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -241,7 +241,7 @@ class MathematicaParser:\n         tokens.extend(map(re.escape, tokens_escape))\n         tokens.append(',')\n         tokens.append('\\n')\n-        tokenizer = re.compile('(' + '|'.join(tokens) + ')')\n+        tokenizer = re.compile('(' + '|'.join(tokens) + ')', re.UNICODE)\n         self._regex_tokenizer = tokenizer\n         return self._regex_tokenizer\n     def _from_mathematica_to_tokens(self, code: str):\n", "normalized_occurrence": 3}
