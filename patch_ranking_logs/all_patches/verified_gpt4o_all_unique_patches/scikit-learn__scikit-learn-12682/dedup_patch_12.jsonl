{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-12682", "model_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex 8cfbe5f..80da592 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -313,7 +313,7 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',\n                               max_iter=max_iter,\n                               check_input=False,\n                               verbose=verbose,\n-                              positive=positive)\n+                              positive=positive, max_iter=self.max_iter)\n         return code\n \n     # Enter parallel code block\n@@ -990,8 +990,9 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n     _required_parameters = [\"dictionary\"]\n \n     def __init__(self, dictionary, transform_algorithm='omp',\n-                 transform_n_nonzero_coefs=None, transform_alpha=None,\n+                 transform_n_nonzero_coefs=None, transform_alpha=None, max_iter=1000,\n                  split_sign=False, n_jobs=None, positive_code=False):\n+        self.max_iter = max_iter\n         self._set_sparse_coding_params(dictionary.shape[0],\n                                        transform_algorithm,\n                                        transform_n_nonzero_coefs,\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex 8a206a7..2fe9ea3 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -83,7 +83,7 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars', n_\n         if regularization is None:\n             regularization = 1.0\n     if effective_n_jobs(n_jobs) == 1 or algorithm == 'threshold':\n-        code = _sparse_encode(X, dictionary, gram, cov=cov, algorithm=algorithm, regularization=regularization, copy_cov=copy_cov, init=init, max_iter=max_iter, check_input=False, verbose=verbose, positive=positive)\n+        code = _sparse_encode(X, dictionary, gram, cov=cov, algorithm=algorithm, regularization=regularization, copy_cov=copy_cov, init=init, max_iter=max_iter, check_input=False, verbose=verbose, positive=positive, max_iter=self.max_iter)\n         return code\n     code = np.empty((n_samples, n_components))\n     slices = list(gen_even_slices(n_samples, effective_n_jobs(n_jobs)))\n@@ -284,7 +284,8 @@ class SparseCodingMixin(TransformerMixin):\n         return code\n class SparseCoder(BaseEstimator, SparseCodingMixin):\n     _required_parameters = ['dictionary']\n-    def __init__(self, dictionary, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, split_sign=False, n_jobs=None, positive_code=False):\n+    def __init__(self, dictionary, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, max_iter=1000, split_sign=False, n_jobs=None, positive_code=False):\n+        self.max_iter = max_iter\n         self._set_sparse_coding_params(dictionary.shape[0], transform_algorithm, transform_n_nonzero_coefs, transform_alpha, split_sign, n_jobs, positive_code)\n         self.components_ = dictionary\n     def fit(self, X, y=None):\n", "normalized_occurrence": 1}
