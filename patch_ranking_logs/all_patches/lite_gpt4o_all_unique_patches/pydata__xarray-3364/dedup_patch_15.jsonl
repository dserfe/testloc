{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-3364", "model_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex 1ac1b8e..601285d 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -1,3 +1,4 @@\n+\n import pandas as pd\n \n from . import dtypes, utils\n@@ -313,11 +314,11 @@ def _dataset_concat(\n \n         for ds in datasets:\n             absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+            for var in absent_merge_vars:\n+                var_dims = datasets[0][var].dims\n+                var_shape = tuple(dims_sizes.get(dim, 1) for dim in var_dims)\n+                dummy_data = np.full(var_shape, fill_value, dtype=datasets[0][var].dtype)\n+                ds[var] = (var_dims, dummy_data)\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -368,11 +369,11 @@ def _dataset_concat(\n \n     result = Dataset(result_vars, attrs=result_attrs)\n     absent_coord_names = coord_names - set(result.variables)\n-    if absent_coord_names:\n-        raise ValueError(\n-            \"Variables %r are coordinates in some datasets but not others.\"\n-            % absent_coord_names\n-        )\n+    for coord_name in absent_coord_names:\n+        var_dims = datasets[0][coord_name].dims\n+        var_shape = tuple(dims_sizes.get(dim, 1) for dim in var_dims)\n+        dummy_data = np.full(var_shape, fill_value, dtype=datasets[0][coord_name].dtype)\n+        result[coord_name] = (var_dims, dummy_data)\n     result = result.set_coords(coord_names)\n     result.encoding = result_encoding\n \n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex 06e5a50..41558f8 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -127,8 +127,11 @@ def _dataset_concat(datasets, dim, data_vars, coords, compat, positions, fill_va\n         to_merge = {var: [] for var in variables_to_merge}\n         for ds in datasets:\n             absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError('variables %r are present in some datasets but not others. ' % absent_merge_vars)\n+            for var in absent_merge_vars:\n+                var_dims = datasets[0][var].dims\n+                var_shape = tuple((dims_sizes.get(dim, 1) for dim in var_dims))\n+                dummy_data = np.full(var_shape, fill_value, dtype=datasets[0][var].dtype)\n+                ds[var] = (var_dims, dummy_data)\n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n         for var in variables_to_merge:\n@@ -161,8 +164,11 @@ def _dataset_concat(datasets, dim, data_vars, coords, compat, positions, fill_va\n             result_vars[k] = combined\n     result = Dataset(result_vars, attrs=result_attrs)\n     absent_coord_names = coord_names - set(result.variables)\n-    if absent_coord_names:\n-        raise ValueError('Variables %r are coordinates in some datasets but not others.' % absent_coord_names)\n+    for coord_name in absent_coord_names:\n+        var_dims = datasets[0][coord_name].dims\n+        var_shape = tuple((dims_sizes.get(dim, 1) for dim in var_dims))\n+        dummy_data = np.full(var_shape, fill_value, dtype=datasets[0][coord_name].dtype)\n+        result[coord_name] = (var_dims, dummy_data)\n     result = result.set_coords(coord_names)\n     result.encoding = result_encoding\n     result = result.drop(unlabeled_dims, errors='ignore')\n", "normalized_occurrence": 1}
