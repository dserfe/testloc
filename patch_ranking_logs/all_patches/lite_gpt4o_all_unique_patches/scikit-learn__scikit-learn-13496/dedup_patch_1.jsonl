{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13496", "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 17608bc..14ba94c 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -173,7 +173,9 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n+                 verbose=0,\n+                 warm_start=False):\n+        self.warm_start = warm_start\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n@@ -221,7 +223,12 @@ class IsolationForest(BaseBagging, OutlierMixin):\n         Returns\n         -------\n         self : object\n-        \"\"\"\n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n+    \"\"\"\n         if self.contamination == \"legacy\":\n             warn('default contamination parameter 0.1 will change '\n                  'in version 0.22 to \"auto\". This will change the '\n@@ -320,7 +327,12 @@ class IsolationForest(BaseBagging, OutlierMixin):\n         is_inlier : array, shape (n_samples,)\n             For each observation, tells whether or not (+1 or -1) it should\n             be considered as an inlier according to the fitted model.\n-        \"\"\"\n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n+    \"\"\"\n         check_is_fitted(self, [\"offset_\"])\n         X = check_array(X, accept_sparse='csr')\n         is_inlier = np.ones(X.shape[0], dtype=int)\n@@ -354,7 +366,12 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             The lower, the more abnormal. Negative scores represent outliers,\n             positive scores represent inliers.\n \n-        \"\"\"\n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n+    \"\"\"\n         # We subtract self.offset_ to make 0 be the threshold value for being\n         # an outlier:\n \n@@ -382,7 +399,12 @@ class IsolationForest(BaseBagging, OutlierMixin):\n         scores : array, shape (n_samples,)\n             The anomaly score of the input samples.\n             The lower, the more abnormal.\n-        \"\"\"\n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n+    \"\"\"\n         # code structure from ForestClassifier/predict_proba\n         check_is_fitted(self, [\"estimators_\"])\n \n@@ -448,7 +470,12 @@ class IsolationForest(BaseBagging, OutlierMixin):\n \n         subsample_features : bool,\n             whether features should be subsampled\n-        \"\"\"\n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n+    \"\"\"\n         n_samples = X.shape[0]\n \n         depths = np.zeros(n_samples, order=\"f\")\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 3ca6fb5..898f763 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -11,7 +11,8 @@ from .bagging import BaseBagging\n __all__ = ['IsolationForest']\n INTEGER_TYPES = (numbers.Integral, np.integer)\n class IsolationForest(BaseBagging, OutlierMixin):\n-    def __init__(self, n_estimators=100, max_samples='auto', contamination='legacy', max_features=1.0, bootstrap=False, n_jobs=None, behaviour='old', random_state=None, verbose=0):\n+    def __init__(self, n_estimators=100, max_samples='auto', contamination='legacy', max_features=1.0, bootstrap=False, n_jobs=None, behaviour='old', random_state=None, verbose=0, warm_start=False):\n+        self.warm_start = warm_start\n         super().__init__(base_estimator=ExtraTreeRegressor(max_features=1, splitter='random', random_state=random_state), bootstrap=bootstrap, bootstrap_features=False, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, n_jobs=n_jobs, random_state=random_state, verbose=verbose)\n         self.behaviour = behaviour\n         self.contamination = contamination\n", "normalized_occurrence": 12}
