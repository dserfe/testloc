{"model_name_or_path": "agentless_claude", "instance_id": "pylint-dev__pylint-4970", "model_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 79a566f..84462f4 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -234,8 +234,10 @@ def hash_lineset(\n     :param lineset: lineset object (i.e the lines in a file)\n     :param min_common_lines: number of successive lines that are used to compute the hash\n     :return: a dict linking hashes to corresponding start index and a dict that links this\n-             index to the start and end lines in the file\n+             index to the start and end lines in the file. Returns empty dicts if min_common_lines is 0.\n     \"\"\"\n+    if min_common_lines == 0:\n+        return defaultdict(list), {}\n     hash2index = defaultdict(list)\n     index2lines = {}\n     # Comments, docstring and other specific patterns maybe excluded -> call to stripped_lines\n@@ -470,7 +472,11 @@ class Similar:\n         the couple of corresponding starting and ending lines in both files.\n         Last regroups all successive couples in a bigger one. It allows to take into account common chunk of lines that have more\n         than the minimal number of successive lines required.\n+\n+        If min_lines is 0, duplicate code checking is disabled.\n         \"\"\"\n+        if self.min_lines == 0:\n+            return\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n", "occurrence": 1, "normalized_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 0997b2e..a58f727 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -77,6 +77,8 @@ class LineSetStartCouple(NamedTuple):\n         return LineSetStartCouple(Index(self.fst_lineset_index + value), Index(self.snd_lineset_index + value))\n LinesChunkLimits_T = Tuple['LineSet', LineNumber, LineNumber]\n def hash_lineset(lineset: 'LineSet', min_common_lines: int=DEFAULT_MIN_SIMILARITY_LINE) -> Tuple[HashToIndex_T, IndexToLines_T]:\n+    if min_common_lines == 0:\n+        return (defaultdict(list), {})\n     hash2index = defaultdict(list)\n     index2lines = {}\n     lines = tuple((x.text for x in lineset.stripped_lines))\n@@ -185,6 +187,8 @@ class Similar:\n         report += f'TOTAL lines={total_line_number} duplicates={duplicated_line_number} percent={duplicated_line_number * 100.0 / total_line_number:.2f}\\n'\n         return report\n     def _find_common(self, lineset1: 'LineSet', lineset2: 'LineSet') -> Generator[Commonality, None, None]:\n+        if self.min_lines == 0:\n+            return\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n", "normalized_occurrence": 2}
