{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13439", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 4594f40..4b84599 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -27,6 +27,8 @@ __all__ = ['Pipeline', 'FeatureUnion', 'make_pipeline', 'make_union']\n \n \n class Pipeline(_BaseComposition):\n+    def __len__(self):\n+        return len(self.steps)\n     \"\"\"Pipeline of transforms with a final estimator.\n \n     Sequentially apply a list of transforms and a final estimator.\n", "occurrence": 1, "normalized_patch": "--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n+    def __len__(self):\n+        return len(self.steps)\n+    \"Pipeline of transforms with a final estimator.\\n\\n    Sequentially apply a list of transforms and a final estimator.\\n    Intermediate steps of the pipeline must be 'transforms', that is, they\\n    must implement fit and transform methods.\\n    The final estimator only needs to implement fit.\\n    The transformers in the pipeline can be cached using ``memory`` argument.\\n\\n    The purpose of the pipeline is to assemble several steps that can be\\n    cross-validated together while setting different parameters.\\n    For this, it enables setting parameters of the various steps using their\\n    names and the parameter name separated by a '__', as in the example below.\\n    A step's estimator may be replaced entirely by setting the parameter\\n    with its name to another estimator, or a transformer removed by setting\\n    it to 'passthrough' or ``None``.\\n\\n    Read more in the :ref:`User Guide <pipeline>`.\\n\\n    Parameters\\n    ----------\\n    steps : list\\n        List of (name, transform) tuples (implementing fit/transform) that are\\n        chained, in the order in which they are chained, with the last object\\n        an estimator.\\n\\n    memory : None, str or object with the joblib.Memory interface, optional\\n        Used to cache the fitted transformers of the pipeline. By default,\\n        no caching is performed. If a string is given, it is the path to\\n        the caching directory. Enabling caching triggers a clone of\\n        the transformers before fitting. Therefore, the transformer\\n        instance given to the pipeline cannot be inspected\\n        directly. Use the attribute ``named_steps`` or ``steps`` to\\n        inspect estimators within the pipeline. Caching the\\n        transformers is advantageous when fitting is time consuming.\\n\\n    Attributes\\n    ----------\\n    named_steps : bunch object, a dictionary with attribute access\\n        Read-only attribute to access any step parameter by user given name.\\n        Keys are step names and values are steps parameters.\\n\\n    See also\\n    --------\\n    sklearn.pipeline.make_pipeline : convenience function for simplified\\n        pipeline construction.\\n\\n    Examples\\n    --------\\n    >>> from sklearn import svm\\n    >>> from sklearn.datasets import samples_generator\\n    >>> from sklearn.feature_selection import SelectKBest\\n    >>> from sklearn.feature_selection import f_regression\\n    >>> from sklearn.pipeline import Pipeline\\n    >>> # generate some data to play with\\n    >>> X, y = samples_generator.make_classification(\\n    ...     n_informative=5, n_redundant=0, random_state=42)\\n    >>> # ANOVA SVM-C\\n    >>> anova_filter = SelectKBest(f_regression, k=5)\\n    >>> clf = svm.SVC(kernel='linear')\\n    >>> anova_svm = Pipeline([('anova', anova_filter), ('svc', clf)])\\n    >>> # You can set the parameters using the names issued\\n    >>> # For instance, fit using a k of 10 in the SelectKBest\\n    >>> # and a parameter 'C' of the svm\\n    >>> anova_svm.set_params(anova__k=10, svc__C=.1).fit(X, y)\\n    ...                      # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\\n    Pipeline(memory=None,\\n             steps=[('anova', SelectKBest(...)),\\n                    ('svc', SVC(...))])\\n    >>> prediction = anova_svm.predict(X)\\n    >>> anova_svm.score(X, y)                        # doctest: +ELLIPSIS\\n    0.83\\n    >>> # getting the selected features chosen by anova_filter\\n    >>> anova_svm['anova'].get_support()\\n    ... # doctest: +NORMALIZE_WHITESPACE\\n    array([False, False,  True,  True, False, False,  True,  True, False,\\n           True, False,  True,  True, False,  True, False,  True,  True,\\n           False, False])\\n    >>> # Another way to get selected features chosen by anova_filter\\n    >>> anova_svm.named_steps.anova.get_support()\\n    ... # doctest: +NORMALIZE_WHITESPACE\\n    array([False, False,  True,  True, False, False,  True,  True, False,\\n           True, False,  True,  True, False,  True, False,  True,  True,\\n           False, False])\\n    >>> # Indexing can also be used to extract a sub-pipeline.\\n    >>> sub_pipeline = anova_svm[:1]\\n    >>> sub_pipeline  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\\n    Pipeline(memory=None, steps=[('anova', ...)])\\n    >>> coef = anova_svm[-1].coef_\\n    >>> anova_svm['svc'] is anova_svm[-1]\\n    True\\n    >>> coef.shape\\n    (1, 10)\\n    >>> sub_pipeline.inverse_transform(coef).shape\\n    (1, 20)\\n    \"", "normalized_occurrence": 2}
