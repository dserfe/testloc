{"model_name_or_path": "agentless", "instance_id": "pytest-dev__pytest-7490", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 1316da9..02ecf6c 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -238,18 +238,14 @@ def pytest_runtest_setup(item: Item) -> None:\n         item._store[skipped_by_mark_key] = True\n         skip(skipped.reason)\n \n-    if not item.config.option.runxfail:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n-        if xfailed and not xfailed.run:\n-            xfail(\"[NOTRUN] \" + xfailed.reason)\n+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+    if xfailed and not xfailed.run:\n+        xfail(\"[NOTRUN] \" + xfailed.reason)\n \n \n @hookimpl(hookwrapper=True)\n def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n     xfailed = item._store.get(xfailed_key, None)\n-    if xfailed is None:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n-\n     if not item.config.option.runxfail:\n         if xfailed and not xfailed.run:\n             xfail(\"[NOTRUN] \" + xfailed.reason)\n@@ -312,4 +308,4 @@ def pytest_report_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str\n             return \"xfailed\", \"x\", \"XFAIL\"\n         elif report.passed:\n             return \"xpassed\", \"X\", \"XPASS\"\n-    return None\n+    return None\n", "occurrence": 1, "normalized_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex d85ae4c..645263f 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -123,15 +123,12 @@ def pytest_runtest_setup(item: Item) -> None:\n     if skipped:\n         item._store[skipped_by_mark_key] = True\n         skip(skipped.reason)\n-    if not item.config.option.runxfail:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n-        if xfailed and (not xfailed.run):\n-            xfail('[NOTRUN] ' + xfailed.reason)\n+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+    if xfailed and (not xfailed.run):\n+        xfail('[NOTRUN] ' + xfailed.reason)\n @hookimpl(hookwrapper=True)\n def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n     xfailed = item._store.get(xfailed_key, None)\n-    if xfailed is None:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n     if not item.config.option.runxfail:\n         if xfailed and (not xfailed.run):\n             xfail('[NOTRUN] ' + xfailed.reason)\n", "normalized_occurrence": 1}
