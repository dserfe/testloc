{"model_name_or_path": "agentless", "instance_id": "pytest-dev__pytest-7490", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 1316da9..8ce8449 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -238,20 +238,17 @@ def pytest_runtest_setup(item: Item) -> None:\n         item._store[skipped_by_mark_key] = True\n         skip(skipped.reason)\n \n+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n     if not item.config.option.runxfail:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n         if xfailed and not xfailed.run:\n             xfail(\"[NOTRUN] \" + xfailed.reason)\n \n \n @hookimpl(hookwrapper=True)\n def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n-    xfailed = item._store.get(xfailed_key, None)\n-    if xfailed is None:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n-\n-    if not item.config.option.runxfail:\n-        if xfailed and not xfailed.run:\n+    xfailed = item._store.get(xfailed_key, evaluate_xfail_marks(item))\n+    if not item.config.option.runxfail and xfailed:\n+        if not xfailed.run:\n             xfail(\"[NOTRUN] \" + xfailed.reason)\n \n     yield\n@@ -261,7 +258,7 @@ def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n     rep = outcome.get_result()\n-    xfailed = item._store.get(xfailed_key, None)\n+    xfailed = item._store.get(xfailed_key, evaluate_xfail_marks(item))\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]\n@@ -312,4 +309,4 @@ def pytest_report_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str\n             return \"xfailed\", \"x\", \"XFAIL\"\n         elif report.passed:\n             return \"xpassed\", \"X\", \"XPASS\"\n-    return None\n+    return None\n", "occurrence": 1, "normalized_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex d85ae4c..e71e9d7 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -123,24 +123,22 @@ def pytest_runtest_setup(item: Item) -> None:\n     if skipped:\n         item._store[skipped_by_mark_key] = True\n         skip(skipped.reason)\n+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n     if not item.config.option.runxfail:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n         if xfailed and (not xfailed.run):\n             xfail('[NOTRUN] ' + xfailed.reason)\n @hookimpl(hookwrapper=True)\n def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n-    xfailed = item._store.get(xfailed_key, None)\n-    if xfailed is None:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n-    if not item.config.option.runxfail:\n-        if xfailed and (not xfailed.run):\n+    xfailed = item._store.get(xfailed_key, evaluate_xfail_marks(item))\n+    if not item.config.option.runxfail and xfailed:\n+        if not xfailed.run:\n             xfail('[NOTRUN] ' + xfailed.reason)\n     yield\n @hookimpl(hookwrapper=True)\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = (yield)\n     rep = outcome.get_result()\n-    xfailed = item._store.get(xfailed_key, None)\n+    xfailed = item._store.get(xfailed_key, evaluate_xfail_marks(item))\n     if unexpectedsuccess_key in item._store and rep.when == 'call':\n         reason = item._store[unexpectedsuccess_key]\n         if reason:\n", "normalized_occurrence": 1}
