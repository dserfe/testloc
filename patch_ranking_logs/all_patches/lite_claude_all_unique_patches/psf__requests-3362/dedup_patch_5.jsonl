{"model_name_or_path": "agentless_claude", "instance_id": "psf__requests-3362", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 58593f5..d9ac666 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -692,10 +692,18 @@ class Response(object):\n \n         stream_chunks = generate()\n \n-        chunks = reused_chunks if self._content_consumed else stream_chunks\n-\n-        if decode_unicode:\n-            chunks = stream_decode_response_unicode(chunks, self)\n+        if self._content_consumed:\n+            if decode_unicode and isinstance(self._content, bytes):\n+                # Only decode consumed content if it's bytes and decode_unicode=True\n+                decoder = codecs.getincrementaldecoder(self.encoding or 'utf-8')(errors='replace')\n+                chunks = (decoder.decode(chunk, final=(i == len(self._content) - 1))\n+                         for i, chunk in enumerate(reused_chunks))\n+            else:\n+                chunks = reused_chunks\n+        else:\n+            chunks = stream_chunks\n+            if decode_unicode:\n+                chunks = stream_decode_response_unicode(chunks, self)\n \n         return chunks\n \n", "occurrence": 1, "normalized_patch": "diff --git a/requests/models.py b/requests/models.py\nindex d66e2b7..e5f0175 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -358,9 +358,16 @@ class Response(object):\n             raise TypeError('chunk_size must be an int, it is instead a %s.' % type(chunk_size))\n         reused_chunks = iter_slices(self._content, chunk_size)\n         stream_chunks = generate()\n-        chunks = reused_chunks if self._content_consumed else stream_chunks\n-        if decode_unicode:\n-            chunks = stream_decode_response_unicode(chunks, self)\n+        if self._content_consumed:\n+            if decode_unicode and isinstance(self._content, bytes):\n+                decoder = codecs.getincrementaldecoder(self.encoding or 'utf-8')(errors='replace')\n+                chunks = (decoder.decode(chunk, final=i == len(self._content) - 1) for i, chunk in enumerate(reused_chunks))\n+            else:\n+                chunks = reused_chunks\n+        else:\n+            chunks = stream_chunks\n+            if decode_unicode:\n+                chunks = stream_decode_response_unicode(chunks, self)\n         return chunks\n     def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):\n         pending = None\n", "normalized_occurrence": 1}
