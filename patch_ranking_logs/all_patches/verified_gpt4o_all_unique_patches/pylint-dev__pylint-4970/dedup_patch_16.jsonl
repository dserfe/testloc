{"model_name_or_path": "agentless", "instance_id": "pylint-dev__pylint-4970", "model_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 79a566f..4a9d4da 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -475,6 +475,8 @@ class Similar:\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n         index_to_lines_2: IndexToLines_T\n+        if self.min_lines == 0:\n+            return\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n \n@@ -531,6 +533,8 @@ class Similar:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+        if self.min_lines == 0:\n+            return\n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -830,6 +834,8 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n \n     def close(self):\n         \"\"\"compute and display similarities on closing (i.e. end of parsing)\"\"\"\n+        if self.min_lines == 0:\n+            return\n         total = sum(len(lineset) for lineset in self.linesets)\n         duplicated = 0\n         stats = self.stats\n", "occurrence": 1, "normalized_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 0997b2e..8b95b2f 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -189,6 +189,8 @@ class Similar:\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n         index_to_lines_2: IndexToLines_T\n+        if self.min_lines == 0:\n+            return\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n         hash_1: FrozenSet[LinesChunk] = frozenset(hash_to_index_1.keys())\n@@ -210,6 +212,8 @@ class Similar:\n             if eff_cmn_nb > self.min_lines:\n                 yield com\n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        if self.min_lines == 0:\n+            return\n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1:]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -321,6 +325,8 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         with node.stream() as stream:\n             self.append_stream(self.linter.current_name, stream, node.file_encoding)\n     def close(self):\n+        if self.min_lines == 0:\n+            return\n         total = sum((len(lineset) for lineset in self.linesets))\n         duplicated = 0\n         stats = self.stats\n", "normalized_occurrence": 1}
