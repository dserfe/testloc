{"model_name_or_path": "agentless_claude", "instance_id": "django__django-14053", "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 04c866a..2c43898 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -242,6 +242,54 @@ class HashedFilesMixin:\n             if not substitutions:\n                 break\n \n+    def post_process(self, paths, dry_run=False, **options):\n+        \"\"\"\n+        Post process the given dictionary of files (called from collectstatic).\n+\n+        Processing is actually two separate operations:\n+\n+        1. renaming files to include a hash of their content for cache-busting,\n+           and copying those files to the target storage.\n+        2. adjusting files which contain references to other files so they\n+           refer to the cache-busting filenames.\n+\n+        If either of these are performed on a file, then that file is considered\n+        post-processed.\n+        \"\"\"\n+        # don't even dare to process the files if we're in dry run mode\n+        if dry_run:\n+            return\n+\n+        # where to store the new paths\n+        hashed_files = {}\n+\n+        # build a list of adjustable files\n+        adjustable_paths = [\n+            path for path in paths\n+            if matches_patterns(path, self._patterns)\n+        ]\n+        \n+        # Process all files first time\n+        processed_files = set()\n+        for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n+            if processed:\n+                processed_files.add(name)\n+                yield name, hashed_name, processed\n+\n+        # Only process adjustable files in subsequent passes\n+        paths = {path: paths[path] for path in adjustable_paths}\n+\n+        for i in range(self.max_post_process_passes):\n+            substitutions = False\n+            for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n+                if processed and subst and name not in processed_files:\n+                    processed_files.add(name)\n+                    yield name, hashed_name, processed\n+                substitutions = substitutions or subst\n+\n+            if not substitutions:\n+                break\n+\n         if substitutions:\n             yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n \n", "occurrence": 1, "normalized_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 08bad89..670bd66 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -136,6 +136,26 @@ class HashedFilesMixin:\n                 substitutions = substitutions or subst\n             if not substitutions:\n                 break\n+    def post_process(self, paths, dry_run=False, **options):\n+        if dry_run:\n+            return\n+        hashed_files = {}\n+        adjustable_paths = [path for path in paths if matches_patterns(path, self._patterns)]\n+        processed_files = set()\n+        for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n+            if processed:\n+                processed_files.add(name)\n+                yield (name, hashed_name, processed)\n+        paths = {path: paths[path] for path in adjustable_paths}\n+        for i in range(self.max_post_process_passes):\n+            substitutions = False\n+            for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n+                if processed and subst and (name not in processed_files):\n+                    processed_files.add(name)\n+                    yield (name, hashed_name, processed)\n+                substitutions = substitutions or subst\n+            if not substitutions:\n+                break\n         if substitutions:\n             yield ('All', None, RuntimeError('Max post-process passes exceeded.'))\n         self.hashed_files.update(hashed_files)\n", "normalized_occurrence": 2}
