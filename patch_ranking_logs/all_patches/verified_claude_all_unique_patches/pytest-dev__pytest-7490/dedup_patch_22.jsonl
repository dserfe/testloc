{"model_name_or_path": "agentless_claude", "instance_id": "pytest-dev__pytest-7490", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 1316da9..823113f 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -259,6 +259,9 @@ def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n \n @hookimpl(hookwrapper=True)\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n+    # Re-evaluate xfail marks as they might have been dynamically added during test execution\n+    if not item.config.option.runxfail:\n+        item._store[xfailed_key] = evaluate_xfail_marks(item)\n     outcome = yield\n     rep = outcome.get_result()\n     xfailed = item._store.get(xfailed_key, None)\n", "occurrence": 1, "normalized_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex d85ae4c..160ebe5 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -138,6 +138,8 @@ def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n     yield\n @hookimpl(hookwrapper=True)\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n+    if not item.config.option.runxfail:\n+        item._store[xfailed_key] = evaluate_xfail_marks(item)\n     outcome = (yield)\n     rep = outcome.get_result()\n     xfailed = item._store.get(xfailed_key, None)\n", "normalized_occurrence": 1}
