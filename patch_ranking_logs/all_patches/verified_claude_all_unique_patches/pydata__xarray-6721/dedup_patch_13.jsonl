{"model_name_or_path": "agentless_claude", "instance_id": "pydata__xarray-6721", "model_patch": "diff --git a/xarray/core/common.py b/xarray/core/common.py\nindex 304e65c..6c5b83a 100644\n--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -2023,7 +2023,10 @@ def get_chunksizes(\n \n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.data, \"chunks\"):\n+        encoding = getattr(v, 'encoding', {})\n+        if encoding.get('chunks') is not None or hasattr(v, 'chunksizes'):\n+            # If chunksizes is already cached, use it directly\n+            # otherwise it will be computed from encoding['chunks']\n             for dim, c in v.chunksizes.items():\n                 if dim in chunks and c != chunks[dim]:\n                     raise ValueError(\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/common.py b/xarray/core/common.py\nindex 66e6a33..c0268c7 100644\n--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -387,7 +387,8 @@ def ones_like(other: Dataset | DataArray | Variable, dtype: DTypeMaybeMapping=No\n def get_chunksizes(variables: Iterable[Variable]) -> Mapping[Any, tuple[int, ...]]:\n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.data, 'chunks'):\n+        encoding = getattr(v, 'encoding', {})\n+        if encoding.get('chunks') is not None or hasattr(v, 'chunksizes'):\n             for dim, c in v.chunksizes.items():\n                 if dim in chunks and c != chunks[dim]:\n                     raise ValueError(f'Object has inconsistent chunks along dimension {dim}. This can be fixed by calling unify_chunks().')\n", "normalized_occurrence": 1}
