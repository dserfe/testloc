{"model_name_or_path": "agentless_claude", "instance_id": "scikit-learn__scikit-learn-11578", "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex 6a330d0..31eb1d5 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -922,7 +922,18 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(\n+        fit_intercept=fit_intercept,\n+        multi_class=multi_class,\n+        solver=solver,\n+        max_iter=max_iter,\n+        class_weight=class_weight,\n+        penalty=penalty,\n+        dual=dual,\n+        tol=tol,\n+        intercept_scaling=intercept_scaling,\n+        random_state=random_state\n+    )\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\n@@ -931,7 +942,7 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         log_reg.classes_ = np.unique(y_train)\n     else:\n         raise ValueError(\"multi_class should be either multinomial or ovr, \"\n-                         \"got %d\" % multi_class)\n+                         \"got %s\" % multi_class)\n \n     if pos_class is not None:\n         mask = (y_test == pos_class)\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex 22eb338..36f8091 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -276,13 +276,13 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10, scoring=None\n         check_consistent_length(y, sample_weight)\n         sample_weight = sample_weight[train]\n     coefs, Cs, n_iter = logistic_regression_path(X_train, y_train, Cs=Cs, fit_intercept=fit_intercept, solver=solver, max_iter=max_iter, class_weight=class_weight, pos_class=pos_class, multi_class=multi_class, tol=tol, verbose=verbose, dual=dual, penalty=penalty, intercept_scaling=intercept_scaling, random_state=random_state, check_input=False, max_squared_sum=max_squared_sum, sample_weight=sample_weight)\n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(fit_intercept=fit_intercept, multi_class=multi_class, solver=solver, max_iter=max_iter, class_weight=class_weight, penalty=penalty, dual=dual, tol=tol, intercept_scaling=intercept_scaling, random_state=random_state)\n     if multi_class == 'ovr':\n         log_reg.classes_ = np.array([-1, 1])\n     elif multi_class == 'multinomial':\n         log_reg.classes_ = np.unique(y_train)\n     else:\n-        raise ValueError('multi_class should be either multinomial or ovr, got %d' % multi_class)\n+        raise ValueError('multi_class should be either multinomial or ovr, got %s' % multi_class)\n     if pos_class is not None:\n         mask = y_test == pos_class\n         y_test = np.ones(y_test.shape, dtype=np.float64)\n", "normalized_occurrence": 1}
