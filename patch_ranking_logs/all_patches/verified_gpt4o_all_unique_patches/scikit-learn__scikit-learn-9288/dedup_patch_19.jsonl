{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-9288", "model_patch": "diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py\nindex 915d041..91b4444 100644\n--- a/sklearn/cluster/k_means_.py\n+++ b/sklearn/cluster/k_means_.py\n@@ -361,33 +361,14 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',\n         raise ValueError(\"Algorithm must be 'auto', 'full' or 'elkan', got\"\n                          \" %s\" % str(algorithm))\n     if effective_n_jobs(n_jobs) == 1:\n-        # For a single thread, less memory is needed if we just store one set\n-        # of the best results (as opposed to one set per run per thread).\n-        for it in range(n_init):\n-            # run a k-means once\n-            labels, inertia, centers, n_iter_ = kmeans_single(\n-                X, sample_weight, n_clusters, max_iter=max_iter, init=init,\n-                verbose=verbose, precompute_distances=precompute_distances,\n-                tol=tol, x_squared_norms=x_squared_norms,\n-                random_state=random_state)\n-            # determine if these results are the best so far\n-            if best_inertia is None or inertia < best_inertia:\n-                best_labels = labels.copy()\n-                best_centers = centers.copy()\n-                best_inertia = inertia\n-                best_n_iter = n_iter_\n-    else:\n-        # parallelisation of k-means runs\n+        # Use the same parallelization logic for n_init runs even when n_jobs=1\n         seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n-        results = Parallel(n_jobs=n_jobs, verbose=0)(\n-            delayed(kmeans_single)(X, sample_weight, n_clusters,\n-                                   max_iter=max_iter, init=init,\n-                                   verbose=verbose, tol=tol,\n-                                   precompute_distances=precompute_distances,\n-                                   x_squared_norms=x_squared_norms,\n-                                   # Change seed to ensure variety\n-                                   random_state=seed)\n-            for seed in seeds)\n+        results = [kmeans_single(\n+            X, sample_weight, n_clusters, max_iter=max_iter, init=init,\n+            verbose=verbose, tol=tol, precompute_distances=precompute_distances,\n+            x_squared_norms=x_squared_norms, random_state=seed\n+        ) for seed in seeds]\n+        \n         # Get results with the lowest inertia\n         labels, inertia, centers, n_iters = zip(*results)\n         best = np.argmin(inertia)\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py\nindex abcc315..6e76387 100644\n--- a/sklearn/cluster/k_means_.py\n+++ b/sklearn/cluster/k_means_.py\n@@ -107,16 +107,8 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++', precompute_dist\n     else:\n         raise ValueError(\"Algorithm must be 'auto', 'full' or 'elkan', got %s\" % str(algorithm))\n     if effective_n_jobs(n_jobs) == 1:\n-        for it in range(n_init):\n-            labels, inertia, centers, n_iter_ = kmeans_single(X, sample_weight, n_clusters, max_iter=max_iter, init=init, verbose=verbose, precompute_distances=precompute_distances, tol=tol, x_squared_norms=x_squared_norms, random_state=random_state)\n-            if best_inertia is None or inertia < best_inertia:\n-                best_labels = labels.copy()\n-                best_centers = centers.copy()\n-                best_inertia = inertia\n-                best_n_iter = n_iter_\n-    else:\n         seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n-        results = Parallel(n_jobs=n_jobs, verbose=0)((delayed(kmeans_single)(X, sample_weight, n_clusters, max_iter=max_iter, init=init, verbose=verbose, tol=tol, precompute_distances=precompute_distances, x_squared_norms=x_squared_norms, random_state=seed) for seed in seeds))\n+        results = [kmeans_single(X, sample_weight, n_clusters, max_iter=max_iter, init=init, verbose=verbose, tol=tol, precompute_distances=precompute_distances, x_squared_norms=x_squared_norms, random_state=seed) for seed in seeds]\n         labels, inertia, centers, n_iters = zip(*results)\n         best = np.argmin(inertia)\n         best_labels = labels[best]\n", "normalized_occurrence": 1}
