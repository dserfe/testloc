{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-3364", "model_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex 1ac1b8e..04d2d4b 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -1,3 +1,4 @@\n+\n import pandas as pd\n \n from . import dtypes, utils\n@@ -313,11 +314,8 @@ def _dataset_concat(\n \n         for ds in datasets:\n             absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+            for var in absent_merge_vars:\n+                to_merge[var].append(Variable((), fill_value))\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -356,15 +354,17 @@ def _dataset_concat(\n \n     # stack up each variable to fill-out the dataset (in order)\n     # n.b. this loop preserves variable order, needed for groupby.\n-    for k in datasets[0].variables:\n-        if k in concat_over:\n-            try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n-                raise ValueError(\"%r is not present in all datasets.\" % k)\n-            combined = concat_vars(vars, dim, positions)\n-            assert isinstance(combined, Variable)\n-            result_vars[k] = combined\n+    for k in concat_over:\n+        vars = []\n+        for ds in datasets:\n+            if k in ds.variables:\n+                vars.append(ds.variables[k])\n+            else:\n+                vars.append(Variable((), fill_value))\n+        vars = ensure_common_dims(vars)\n+        combined = concat_vars(vars, dim, positions)\n+        assert isinstance(combined, Variable)\n+        result_vars[k] = combined\n \n     result = Dataset(result_vars, attrs=result_attrs)\n     absent_coord_names = coord_names - set(result.variables)\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex 06e5a50..17966ce 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -127,8 +127,8 @@ def _dataset_concat(datasets, dim, data_vars, coords, compat, positions, fill_va\n         to_merge = {var: [] for var in variables_to_merge}\n         for ds in datasets:\n             absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError('variables %r are present in some datasets but not others. ' % absent_merge_vars)\n+            for var in absent_merge_vars:\n+                to_merge[var].append(Variable((), fill_value))\n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n         for var in variables_to_merge:\n@@ -150,15 +150,17 @@ def _dataset_concat(datasets, dim, data_vars, coords, compat, positions, fill_va\n                 common_shape = tuple((dims_sizes.get(d, dim_len) for d in common_dims))\n                 var = var.set_dims(common_dims, common_shape)\n             yield var\n-    for k in datasets[0].variables:\n-        if k in concat_over:\n-            try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n-                raise ValueError('%r is not present in all datasets.' % k)\n-            combined = concat_vars(vars, dim, positions)\n-            assert isinstance(combined, Variable)\n-            result_vars[k] = combined\n+    for k in concat_over:\n+        vars = []\n+        for ds in datasets:\n+            if k in ds.variables:\n+                vars.append(ds.variables[k])\n+            else:\n+                vars.append(Variable((), fill_value))\n+        vars = ensure_common_dims(vars)\n+        combined = concat_vars(vars, dim, positions)\n+        assert isinstance(combined, Variable)\n+        result_vars[k] = combined\n     result = Dataset(result_vars, attrs=result_attrs)\n     absent_coord_names = coord_names - set(result.variables)\n     if absent_coord_names:\n", "normalized_occurrence": 1}
