{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13142", "model_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex a853e4a..b492d99 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -257,10 +257,11 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n                 best_params = self._get_parameters()\n                 best_n_iter = n_iter\n \n-        # Always do a final e-step to guarantee that the labels returned by\n+        # Always do a final e-step and m-step to guarantee that the labels returned by\n         # fit_predict(X) are always consistent with fit(X).predict(X)\n         # for any value of max_iter and tol (and any random_state).\n         _, log_resp = self._e_step(X)\n+        self._m_step(X, log_resp)\n \n         if not self.converged_:\n             warnings.warn('Initialization %d did not converge. '\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex 9518b16..8b1f35c 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -94,6 +94,7 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n                 best_params = self._get_parameters()\n                 best_n_iter = n_iter\n         _, log_resp = self._e_step(X)\n+        self._m_step(X, log_resp)\n         if not self.converged_:\n             warnings.warn('Initialization %d did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.' % (init + 1), ConvergenceWarning)\n         self._set_parameters(best_params)\n", "normalized_occurrence": 1}
