{"model_name_or_path": "agentless_claude", "instance_id": "pydata__xarray-6721", "model_patch": "diff --git a/xarray/core/common.py b/xarray/core/common.py\nindex 304e65c..d4d2a1f 100644\n--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -2023,14 +2023,21 @@ def get_chunksizes(\n \n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.data, \"chunks\"):\n-            for dim, c in v.chunksizes.items():\n-                if dim in chunks and c != chunks[dim]:\n-                    raise ValueError(\n-                        f\"Object has inconsistent chunks along dimension {dim}. \"\n-                        \"This can be fixed by calling unify_chunks().\"\n-                    )\n-                chunks[dim] = c\n+        # First try to get chunks from encoding to avoid loading data\n+        if v.encoding.get('chunks') is not None:\n+            chunksizes = dict(zip(v.dims, v.encoding['chunks']))\n+        elif hasattr(v.data, \"chunks\"):\n+            chunksizes = v.chunksizes\n+        else:\n+            continue\n+            \n+        for dim, c in chunksizes.items():\n+            if dim in chunks and c != chunks[dim]:\n+                raise ValueError(\n+                    f\"Object has inconsistent chunks along dimension {dim}. \"\n+                    \"This can be fixed by calling unify_chunks().\"\n+                )\n+            chunks[dim] = c\n     return Frozen(chunks)\n \n \n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/common.py b/xarray/core/common.py\nindex 66e6a33..465c32e 100644\n--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -387,11 +387,16 @@ def ones_like(other: Dataset | DataArray | Variable, dtype: DTypeMaybeMapping=No\n def get_chunksizes(variables: Iterable[Variable]) -> Mapping[Any, tuple[int, ...]]:\n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.data, 'chunks'):\n-            for dim, c in v.chunksizes.items():\n-                if dim in chunks and c != chunks[dim]:\n-                    raise ValueError(f'Object has inconsistent chunks along dimension {dim}. This can be fixed by calling unify_chunks().')\n-                chunks[dim] = c\n+        if v.encoding.get('chunks') is not None:\n+            chunksizes = dict(zip(v.dims, v.encoding['chunks']))\n+        elif hasattr(v.data, 'chunks'):\n+            chunksizes = v.chunksizes\n+        else:\n+            continue\n+        for dim, c in chunksizes.items():\n+            if dim in chunks and c != chunks[dim]:\n+                raise ValueError(f'Object has inconsistent chunks along dimension {dim}. This can be fixed by calling unify_chunks().')\n+            chunks[dim] = c\n     return Frozen(chunks)\n def is_np_datetime_like(dtype: DTypeLike) -> bool:\n     return np.issubdtype(dtype, np.datetime64) or np.issubdtype(dtype, np.timedelta64)\n", "normalized_occurrence": 1}
