{"model_name_or_path": "agentless_claude", "instance_id": "pydata__xarray-4493", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 8003c0d..1cbfb90 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3907,6 +3907,16 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n             dataset.\n         \"\"\"\n         merge_result = dataset_update_method(self, other)\n+        variables = merge_result.variables\n+        # Ensure we preserve dask arrays in the update\n+        for name, var in variables.items():\n+            if name in self._variables and hasattr(self._variables[name].data, 'chunks'):\n+                if (isinstance(var.data, np.ndarray) and \n+                    var.data.shape == self._variables[name].data.shape):\n+                    from dask.array import from_array\n+                    variables[name] = var.copy(data=from_array(var.data, \n+                                            chunks=self._variables[name].data.chunks))\n+        merge_result = merge_result._replace(variables=variables)\n         return self._replace(inplace=True, **merge_result._asdict())\n \n     def merge(\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 5bd37a8..3e4ded7 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1254,6 +1254,13 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         return result\n     def update(self, other: 'CoercibleMapping') -> 'Dataset':\n         merge_result = dataset_update_method(self, other)\n+        variables = merge_result.variables\n+        for name, var in variables.items():\n+            if name in self._variables and hasattr(self._variables[name].data, 'chunks'):\n+                if isinstance(var.data, np.ndarray) and var.data.shape == self._variables[name].data.shape:\n+                    from dask.array import from_array\n+                    variables[name] = var.copy(data=from_array(var.data, chunks=self._variables[name].data.chunks))\n+        merge_result = merge_result._replace(variables=variables)\n         return self._replace(inplace=True, **merge_result._asdict())\n     def merge(self, other: Union['CoercibleMapping', 'DataArray'], overwrite_vars: Union[Hashable, Iterable[Hashable]]=frozenset(), compat: str='no_conflicts', join: str='outer', fill_value: Any=dtypes.NA) -> 'Dataset':\n         other = other.to_dataset() if isinstance(other, xr.DataArray) else other\n", "normalized_occurrence": 1}
