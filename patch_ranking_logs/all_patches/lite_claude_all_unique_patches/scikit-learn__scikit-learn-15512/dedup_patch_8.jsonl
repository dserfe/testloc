{"model_name_or_path": "agentless_claude", "instance_id": "scikit-learn__scikit-learn-15512", "model_patch": "diff --git a/sklearn/cluster/_affinity_propagation.py b/sklearn/cluster/_affinity_propagation.py\nindex 0511594..42aa3f2 100644\n--- a/sklearn/cluster/_affinity_propagation.py\n+++ b/sklearn/cluster/_affinity_propagation.py\n@@ -193,13 +193,22 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n             se = np.sum(e, axis=1)\n             unconverged = (np.sum((se == convergence_iter) + (se == 0))\n                            != n_samples)\n-            if (not unconverged and (K > 0)) or (it == max_iter):\n+            if not unconverged and (K > 0):\n                 if verbose:\n                     print(\"Converged after %d iterations.\" % it)\n                 break\n+            elif it == max_iter:\n+                if verbose:\n+                    print(\"Did not converge\")\n+                # Return empty array for cluster centers and -1 for labels\n+                # when convergence fails\n+                return np.array([]), np.full(n_samples, -1)\n     else:\n         if verbose:\n             print(\"Did not converge\")\n+        # Return empty array for cluster centers and -1 for labels\n+        # when convergence fails\n+        return np.array([]), np.full(n_samples, -1)\n \n     I = np.flatnonzero(E)\n     K = I.size  # Identify exemplars\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/cluster/_affinity_propagation.py b/sklearn/cluster/_affinity_propagation.py\nindex b441de5..1106e7a 100644\n--- a/sklearn/cluster/_affinity_propagation.py\n+++ b/sklearn/cluster/_affinity_propagation.py\n@@ -64,13 +64,18 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n         if it >= convergence_iter:\n             se = np.sum(e, axis=1)\n             unconverged = np.sum((se == convergence_iter) + (se == 0)) != n_samples\n-            if not unconverged and K > 0 or it == max_iter:\n+            if not unconverged and K > 0:\n                 if verbose:\n                     print('Converged after %d iterations.' % it)\n                 break\n+            elif it == max_iter:\n+                if verbose:\n+                    print('Did not converge')\n+                return (np.array([]), np.full(n_samples, -1))\n     else:\n         if verbose:\n             print('Did not converge')\n+        return (np.array([]), np.full(n_samples, -1))\n     I = np.flatnonzero(E)\n     K = I.size\n     if K > 0:\n", "normalized_occurrence": 1}
