{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-4094", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 1e17b93..16c805b 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3476,9 +3476,12 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         # input dimensions. This code is messy, so it might be better to just\n         # input a dummy value for the singleton dimension.\n         idx = data_array.indexes[new_dim]\n-        levels = [idx.levels[0]] + [\n-            level.astype(self[level.name].dtype) for level in idx.levels[1:]\n-        ]\n+        levels = [idx.levels[0]]\n+        for level in idx.levels[1:]:\n+            if level.name in self:\n+                levels.append(level.astype(self[level.name].dtype))\n+            else:\n+                levels.append(level)\n         new_idx = idx.set_levels(levels)\n         data_array[new_dim] = IndexVariable(new_dim, new_idx)\n \n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 21ef2a4..10c74bd 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1157,7 +1157,12 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         stackable_vars = [ensure_stackable(self[key]) for key in self.data_vars]\n         data_array = xr.concat(stackable_vars, dim=new_dim)\n         idx = data_array.indexes[new_dim]\n-        levels = [idx.levels[0]] + [level.astype(self[level.name].dtype) for level in idx.levels[1:]]\n+        levels = [idx.levels[0]]\n+        for level in idx.levels[1:]:\n+            if level.name in self:\n+                levels.append(level.astype(self[level.name].dtype))\n+            else:\n+                levels.append(level)\n         new_idx = idx.set_levels(levels)\n         data_array[new_dim] = IndexVariable(new_dim, new_idx)\n         if name is not None:\n", "normalized_occurrence": 1}
