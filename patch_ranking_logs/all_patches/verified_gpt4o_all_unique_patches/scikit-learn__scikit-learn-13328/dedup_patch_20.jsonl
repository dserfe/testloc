{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13328", "model_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 774a22b..c691ad2 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -48,6 +48,9 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n         Returns the derivative of the Huber loss with respect to each\n         coefficient, intercept and the scale as a vector.\n     \"\"\"\n+    # Ensure X is of float type to avoid TypeError with boolean arrays\n+    if X.dtype == bool:\n+        X = X.astype(float)\n     _, n_features = X.shape\n     fit_intercept = (n_features + 2 == w.shape[0])\n     if fit_intercept:\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 81acf45..0508dbf 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -7,6 +7,8 @@ from ..utils import check_consistent_length\n from ..utils import axis0_safe_slice\n from ..utils.extmath import safe_sparse_dot\n def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n+    if X.dtype == bool:\n+        X = X.astype(float)\n     _, n_features = X.shape\n     fit_intercept = n_features + 2 == w.shape[0]\n     if fit_intercept:\n", "normalized_occurrence": 2}
