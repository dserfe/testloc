{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-24102", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 3e3bc62..c5802f9 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -586,7 +586,7 @@ class MathematicaParser:\n         \"##\": lambda: [\"SlotSequence\", \"1\"],\n     }\n \n-    _literal = r\"[A-Za-z][A-Za-z0-9]*\"\n+    _literal = r\"[A-Za-z\\u0370-\\u03FF][A-Za-z0-9\\u0370-\\u03FF]*\"\n     _number = r\"(?:[0-9]+(?:\\.[0-9]*)?|\\.[0-9]+)\"\n \n     _enclosure_open = [\"(\", \"[\", \"[[\", \"{\"]\n@@ -606,7 +606,7 @@ class MathematicaParser:\n         if self._regex_tokenizer is not None:\n             # Check if the regular expression has already been compiled:\n             return self._regex_tokenizer\n-        tokens = [self._literal, self._number]\n+        tokens = [self._literal, self._number, r\"[^\\x00-\\x7F]\"]\n         tokens_escape = self._enclosure_open[:] + self._enclosure_close[:]\n         for typ, strat, symdict in self._mathematica_op_precedence:\n             for k in symdict:\n@@ -1076,4 +1076,4 @@ class MathematicaParser:\n         expr = mform\n         for mma_form, sympy_node in self._node_conversions.items():\n             expr = expr.replace(Function(mma_form), sympy_node)\n-        return expr\n+        return expr\n", "occurrence": 1, "normalized_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 957d6fe..482ea11 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -218,7 +218,7 @@ class MathematicaParser:\n     LEFT = 'Left'\n     _mathematica_op_precedence: List[tTuple[str, Optional[str], tDict[str, tUnion[str, Callable]]]] = [(POSTFIX, None, {';': lambda x: x + ['Null'] if isinstance(x, list) and x and (x[0] == 'CompoundExpression') else ['CompoundExpression', x, 'Null']}), (INFIX, FLAT, {';': 'CompoundExpression'}), (INFIX, RIGHT, {'=': 'Set', ':=': 'SetDelayed', '+=': 'AddTo', '-=': 'SubtractFrom', '*=': 'TimesBy', '/=': 'DivideBy'}), (INFIX, LEFT, {'//': lambda x, y: [x, y]}), (POSTFIX, None, {'&': 'Function'}), (INFIX, LEFT, {'/.': 'ReplaceAll'}), (INFIX, RIGHT, {'->': 'Rule', ':>': 'RuleDelayed'}), (INFIX, LEFT, {'/;': 'Condition'}), (INFIX, FLAT, {'|': 'Alternatives'}), (POSTFIX, None, {'..': 'Repeated', '...': 'RepeatedNull'}), (INFIX, FLAT, {'||': 'Or'}), (INFIX, FLAT, {'&&': 'And'}), (PREFIX, None, {'!': 'Not'}), (INFIX, FLAT, {'===': 'SameQ', '=!=': 'UnsameQ'}), (INFIX, FLAT, {'==': 'Equal', '!=': 'Unequal', '<=': 'LessEqual', '<': 'Less', '>=': 'GreaterEqual', '>': 'Greater'}), (INFIX, None, {';;': 'Span'}), (INFIX, FLAT, {'+': 'Plus', '-': 'Plus'}), (INFIX, FLAT, {'*': 'Times', '/': 'Times'}), (INFIX, FLAT, {'.': 'Dot'}), (PREFIX, None, {'-': lambda x: MathematicaParser._get_neg(x), '+': lambda x: x}), (INFIX, RIGHT, {'^': 'Power'}), (INFIX, RIGHT, {'@@': 'Apply', '/@': 'Map', '//@': 'MapAll', '@@@': lambda x, y: ['Apply', x, y, ['List', '1']]}), (POSTFIX, None, {\"'\": 'Derivative', '!': 'Factorial', '!!': 'Factorial2', '--': 'Decrement'}), (INFIX, None, {'[': lambda x, y: [x, *y], '[[': lambda x, y: ['Part', x, *y]}), (PREFIX, None, {'{': lambda x: ['List', *x], '(': lambda x: x[0]}), (INFIX, None, {'?': 'PatternTest'}), (POSTFIX, None, {'_': lambda x: ['Pattern', x, ['Blank']], '_.': lambda x: ['Optional', ['Pattern', x, ['Blank']]], '__': lambda x: ['Pattern', x, ['BlankSequence']], '___': lambda x: ['Pattern', x, ['BlankNullSequence']]}), (INFIX, None, {'_': lambda x, y: ['Pattern', x, ['Blank', y]]}), (PREFIX, None, {'#': 'Slot', '##': 'SlotSequence'})]\n     _missing_arguments_default = {'#': lambda: ['Slot', '1'], '##': lambda: ['SlotSequence', '1']}\n-    _literal = '[A-Za-z][A-Za-z0-9]*'\n+    _literal = '[A-Za-z\\\\u0370-\\\\u03FF][A-Za-z0-9\\\\u0370-\\\\u03FF]*'\n     _number = '(?:[0-9]+(?:\\\\.[0-9]*)?|\\\\.[0-9]+)'\n     _enclosure_open = ['(', '[', '[[', '{']\n     _enclosure_close = [')', ']', ']]', '}']\n@@ -232,7 +232,7 @@ class MathematicaParser:\n     def _get_tokenizer(self):\n         if self._regex_tokenizer is not None:\n             return self._regex_tokenizer\n-        tokens = [self._literal, self._number]\n+        tokens = [self._literal, self._number, '[^\\\\x00-\\\\x7F]']\n         tokens_escape = self._enclosure_open[:] + self._enclosure_close[:]\n         for typ, strat, symdict in self._mathematica_op_precedence:\n             for k in symdict:\n", "normalized_occurrence": 1}
