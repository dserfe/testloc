{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-10297", "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex c320acd..203c925 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -1306,7 +1306,7 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     cv_values_ : array, shape = [n_samples, n_alphas] or \\\n     shape = [n_samples, n_responses, n_alphas], optional\n         Cross-validation values for each alpha (if `store_cv_values=True` and\n-    `cv=None`). After `fit()` has been called, this attribute will contain \\\n+    `cv=None` and `store_cv_values=True`). After `fit()` has been called, this attribute will contain \\\n     the mean squared errors (by default) or the values of the \\\n     `{loss,score}_func` function (if provided in the constructor).\n \n@@ -1333,7 +1333,8 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n+                 normalize=False, scoring=None, cv=None, class_weight=None, store_cv_values=False):\n+        self.store_cv_values = store_cv_values\n         super(RidgeClassifierCV, self).__init__(\n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n             scoring=scoring, cv=cv)\n@@ -1373,9 +1374,9 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n             sample_weight = (sample_weight *\n                              compute_sample_weight(self.class_weight, y))\n \n-        _BaseRidgeCV.fit(self, X, Y, sample_weight=sample_weight)\n+        _BaseRidgeCV.fit(self, X, Y, sample_weight=sample_weight, store_cv_values=self.store_cv_values)\n         return self\n \n     @property\n     def classes_(self):\n-        return self._label_binarizer.classes_\n+        return self._label_binarizer.classes_\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex e8baf60..d517793 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -415,7 +415,8 @@ class _BaseRidgeCV(LinearModel):\n class RidgeCV(_BaseRidgeCV, RegressorMixin):\n     pass\n class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n-    def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True, normalize=False, scoring=None, cv=None, class_weight=None):\n+    def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True, normalize=False, scoring=None, cv=None, class_weight=None, store_cv_values=False):\n+        self.store_cv_values = store_cv_values\n         super(RidgeClassifierCV, self).__init__(alphas=alphas, fit_intercept=fit_intercept, normalize=normalize, scoring=scoring, cv=cv)\n         self.class_weight = class_weight\n     def fit(self, X, y, sample_weight=None):\n@@ -428,7 +429,7 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n             if sample_weight is None:\n                 sample_weight = 1.0\n             sample_weight = sample_weight * compute_sample_weight(self.class_weight, y)\n-        _BaseRidgeCV.fit(self, X, Y, sample_weight=sample_weight)\n+        _BaseRidgeCV.fit(self, X, Y, sample_weight=sample_weight, store_cv_values=self.store_cv_values)\n         return self\n     @property\n     def classes_(self):\n", "normalized_occurrence": 13}
