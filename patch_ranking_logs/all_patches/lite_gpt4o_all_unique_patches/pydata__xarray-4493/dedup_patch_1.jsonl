{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-4493", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 8003c0d..0acdbe4 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3906,8 +3906,12 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n             If any dimensions would have inconsistent sizes in the updated\n             dataset.\n         \"\"\"\n-        merge_result = dataset_update_method(self, other)\n-        return self._replace(inplace=True, **merge_result._asdict())\n+        merge_result = dataset_update_method(self, other, merge_retains_dask=merge_retains_dask)\n+        updated_vars = {\n+            k: (v if not isinstance(v.data, dask.array.Array) else v.copy(deep=False))\n+            for k, v in merge_result.variables.items()\n+        }\n+        return self._replace(inplace=True, variables=updated_vars)\n \n     def merge(\n         self,\n@@ -3916,6 +3920,7 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         compat: str = \"no_conflicts\",\n         join: str = \"outer\",\n         fill_value: Any = dtypes.NA,\n+        merge_retains_dask: bool = True\n     ) -> \"Dataset\":\n         \"\"\"Merge the arrays of two datasets into a single dataset.\n \n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 5bd37a8..7d88374 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1253,9 +1253,10 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n                 result = result._unstack_once(dim, fill_value)\n         return result\n     def update(self, other: 'CoercibleMapping') -> 'Dataset':\n-        merge_result = dataset_update_method(self, other)\n-        return self._replace(inplace=True, **merge_result._asdict())\n-    def merge(self, other: Union['CoercibleMapping', 'DataArray'], overwrite_vars: Union[Hashable, Iterable[Hashable]]=frozenset(), compat: str='no_conflicts', join: str='outer', fill_value: Any=dtypes.NA) -> 'Dataset':\n+        merge_result = dataset_update_method(self, other, merge_retains_dask=merge_retains_dask)\n+        updated_vars = {k: v if not isinstance(v.data, dask.array.Array) else v.copy(deep=False) for k, v in merge_result.variables.items()}\n+        return self._replace(inplace=True, variables=updated_vars)\n+    def merge(self, other: Union['CoercibleMapping', 'DataArray'], overwrite_vars: Union[Hashable, Iterable[Hashable]]=frozenset(), compat: str='no_conflicts', join: str='outer', fill_value: Any=dtypes.NA, merge_retains_dask: bool=True) -> 'Dataset':\n         other = other.to_dataset() if isinstance(other, xr.DataArray) else other\n         merge_result = dataset_merge_method(self, other, overwrite_vars=overwrite_vars, compat=compat, join=join, fill_value=fill_value)\n         return self._replace(**merge_result._asdict())\n", "normalized_occurrence": 1}
