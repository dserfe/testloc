{"model_name_or_path": "agentless_claude", "instance_id": "pydata__xarray-4493", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 8003c0d..a3ae890 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3907,7 +3907,18 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n             dataset.\n         \"\"\"\n         merge_result = dataset_update_method(self, other)\n-        return self._replace(inplace=True, **merge_result._asdict())\n+        variables = merge_result.variables.copy()\n+        # Create new dataset to preserve chunking\n+        ds = self._replace(variables=variables, coord_names=merge_result.coord_names, \n+                          dims=merge_result.dims, attrs=merge_result.attrs, \n+                          indexes=merge_result.indexes, inplace=False)\n+        # Update self with the new dataset's contents\n+        self._variables = ds._variables\n+        self._coord_names = ds._coord_names\n+        self._dims = ds._dims\n+        self._attrs = ds._attrs\n+        self._indexes = ds._indexes\n+        return self\n \n     def merge(\n         self,\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 5bd37a8..af080e7 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1254,7 +1254,14 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         return result\n     def update(self, other: 'CoercibleMapping') -> 'Dataset':\n         merge_result = dataset_update_method(self, other)\n-        return self._replace(inplace=True, **merge_result._asdict())\n+        variables = merge_result.variables.copy()\n+        ds = self._replace(variables=variables, coord_names=merge_result.coord_names, dims=merge_result.dims, attrs=merge_result.attrs, indexes=merge_result.indexes, inplace=False)\n+        self._variables = ds._variables\n+        self._coord_names = ds._coord_names\n+        self._dims = ds._dims\n+        self._attrs = ds._attrs\n+        self._indexes = ds._indexes\n+        return self\n     def merge(self, other: Union['CoercibleMapping', 'DataArray'], overwrite_vars: Union[Hashable, Iterable[Hashable]]=frozenset(), compat: str='no_conflicts', join: str='outer', fill_value: Any=dtypes.NA) -> 'Dataset':\n         other = other.to_dataset() if isinstance(other, xr.DataArray) else other\n         merge_result = dataset_merge_method(self, other, overwrite_vars=overwrite_vars, compat=compat, join=join, fill_value=fill_value)\n", "normalized_occurrence": 1}
