{"model_name_or_path": "agentless_claude", "instance_id": "scikit-learn__scikit-learn-25931", "model_patch": "diff --git a/sklearn/base.py b/sklearn/base.py\nindex e503bfe..0b03018 100644\n--- a/sklearn/base.py\n+++ b/sklearn/base.py\n@@ -448,10 +448,12 @@ class BaseEstimator:\n             return\n \n         if X_feature_names is None and fitted_feature_names is not None:\n-            warnings.warn(\n-                \"X does not have valid feature names, but\"\n-                f\" {self.__class__.__name__} was fitted with feature names\"\n-            )\n+            # Skip the warning if we're still in the fit method\n+            if not hasattr(self, \"_fit_in_progress\"):\n+                warnings.warn(\n+                    \"X does not have valid feature names, but\"\n+                    f\" {self.__class__.__name__} was fitted with feature names\"\n+                )\n             return\n \n         # validate the feature names against the `feature_names_in_` attribute\ndiff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex d995c25..4fff575 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -343,10 +343,17 @@ class IsolationForest(OutlierMixin, BaseBagging):\n             # we take the opposite as we consider the opposite of their score.\n             self.offset_ = -0.5\n             return self\n+            \n+        # Set a marker that we're in the fit process\n+        self._fit_in_progress = True\n \n         # else, define offset_ wrt contamination parameter\n         self.offset_ = np.percentile(self.score_samples(X), 100.0 * self.contamination)\n-\n+        \n+        # Clean up the fit marker\n+        if hasattr(self, \"_fit_in_progress\"):\n+            del self._fit_in_progress\n+            \n         return self\n \n     def predict(self, X):\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/base.py b/sklearn/base.py\nindex f53342c..377d0df 100644\n--- a/sklearn/base.py\n+++ b/sklearn/base.py\n@@ -173,7 +173,8 @@ class BaseEstimator:\n             warnings.warn(f'X has feature names, but {self.__class__.__name__} was fitted without feature names')\n             return\n         if X_feature_names is None and fitted_feature_names is not None:\n-            warnings.warn(f'X does not have valid feature names, but {self.__class__.__name__} was fitted with feature names')\n+            if not hasattr(self, '_fit_in_progress'):\n+                warnings.warn(f'X does not have valid feature names, but {self.__class__.__name__} was fitted with feature names')\n             return\n         if len(fitted_feature_names) != len(X_feature_names) or np.any(fitted_feature_names != X_feature_names):\n             message = 'The feature names should match those that were passed during fit.\\n'\ndiff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex f9e64b9..a965e86 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -46,7 +46,10 @@ class IsolationForest(OutlierMixin, BaseBagging):\n         if self.contamination == 'auto':\n             self.offset_ = -0.5\n             return self\n+        self._fit_in_progress = True\n         self.offset_ = np.percentile(self.score_samples(X), 100.0 * self.contamination)\n+        if hasattr(self, '_fit_in_progress'):\n+            del self._fit_in_progress\n         return self\n     def predict(self, X):\n         check_is_fitted(self)\n", "normalized_occurrence": 1}
