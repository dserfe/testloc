{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-12682", "model_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex 8cfbe5f..d4d6459 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -305,14 +305,10 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',\n             regularization = 1.\n \n     if effective_n_jobs(n_jobs) == 1 or algorithm == 'threshold':\n-        code = _sparse_encode(X,\n-                              dictionary, gram, cov=cov,\n-                              algorithm=algorithm,\n+        code = _sparse_encode(X, dictionary, gram, cov=cov, algorithm=algorithm,\n                               regularization=regularization, copy_cov=copy_cov,\n-                              init=init,\n-                              max_iter=max_iter,\n-                              check_input=False,\n-                              verbose=verbose,\n+                              init=init, max_iter=self.transform_max_iter,\n+                              check_input=False, verbose=verbose,\n                               positive=positive)\n         return code\n \n@@ -933,7 +929,8 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n         normalized to unit norm.\n \n     transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp', \\\n-    'threshold'}\n+    'threshold'},\n+                 transform_max_iter=1000):\n         Algorithm used to transform the data:\n         lars: uses the least angle regression method (linear_model.lars_path)\n         lasso_lars: uses Lars to compute the Lasso solution\n@@ -995,8 +992,10 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n         self._set_sparse_coding_params(dictionary.shape[0],\n                                        transform_algorithm,\n                                        transform_n_nonzero_coefs,\n-                                       transform_alpha, split_sign, n_jobs,\n+                                       transform_alpha, split_sign,\n+                                       transform_max_iter, n_jobs,\n                                        positive_code)\n+        self.transform_max_iter = transform_max_iter\n         self.components_ = dictionary\n \n     def fit(self, X, y=None):\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex 8a206a7..715a94b 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -83,7 +83,7 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars', n_\n         if regularization is None:\n             regularization = 1.0\n     if effective_n_jobs(n_jobs) == 1 or algorithm == 'threshold':\n-        code = _sparse_encode(X, dictionary, gram, cov=cov, algorithm=algorithm, regularization=regularization, copy_cov=copy_cov, init=init, max_iter=max_iter, check_input=False, verbose=verbose, positive=positive)\n+        code = _sparse_encode(X, dictionary, gram, cov=cov, algorithm=algorithm, regularization=regularization, copy_cov=copy_cov, init=init, max_iter=self.transform_max_iter, check_input=False, verbose=verbose, positive=positive)\n         return code\n     code = np.empty((n_samples, n_components))\n     slices = list(gen_even_slices(n_samples, effective_n_jobs(n_jobs)))\n@@ -285,7 +285,8 @@ class SparseCodingMixin(TransformerMixin):\n class SparseCoder(BaseEstimator, SparseCodingMixin):\n     _required_parameters = ['dictionary']\n     def __init__(self, dictionary, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, split_sign=False, n_jobs=None, positive_code=False):\n-        self._set_sparse_coding_params(dictionary.shape[0], transform_algorithm, transform_n_nonzero_coefs, transform_alpha, split_sign, n_jobs, positive_code)\n+        self._set_sparse_coding_params(dictionary.shape[0], transform_algorithm, transform_n_nonzero_coefs, transform_alpha, split_sign, transform_max_iter, n_jobs, positive_code)\n+        self.transform_max_iter = transform_max_iter\n         self.components_ = dictionary\n     def fit(self, X, y=None):\n         return self\n", "normalized_occurrence": 1}
