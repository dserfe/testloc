{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-3151", "model_patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\nindex fe3f23b..f4ca240 100644\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -69,6 +69,25 @@ def _infer_concat_order_from_coords(datasets):\n             # If dimension coordinate values are same on every dataset then\n             # should be leaving this dimension alone (it's just a \"bystander\")\n             if not all(index.equals(indexes[0]) for index in indexes[1:]):\n+                # Infer order datasets should be arranged in along this dim\n+                concat_dims.append(dim)\n+\n+                if all(index.is_monotonic_increasing for index in indexes):\n+                    ascending = True\n+                elif all(index.is_monotonic_decreasing for index in indexes):\n+                    ascending = False\n+                else:\n+                    raise ValueError(\"Coordinate variable {} is neither \"\n+                                     \"monotonically increasing nor \"\n+                                     \"monotonically decreasing on all datasets\"\n+                                     .format(dim))\n+\n+                # Assume that any two datasets whose coord along dim starts\n+                # with the same value have the same coord values throughout.\n+                if any(index.size == 0 for index in indexes):\n+                    raise ValueError('Cannot handle size zero dimensions')\n+                first_items = pd.Index([index.take([0])\n+                                        for index in indexes])\n \n                 # Infer order datasets should be arranged in along this dim\n                 concat_dims.append(dim)\n@@ -504,11 +523,13 @@ def combine_by_coords(datasets, compat='no_conflicts', data_vars='all',\n         for dim in concatenated.dims:\n             if dim in concatenated:\n                 indexes = concatenated.indexes.get(dim)\n-                if not (indexes.is_monotonic_increasing\n-                        or indexes.is_monotonic_decreasing):\n-                    raise ValueError(\"Resulting object does not have monotonic\"\n-                                     \" global indexes along dimension {}\"\n-                                     .format(dim))\n+                # Skip monotonic check if the indexes are all identical\n+                if not all(index.equals(indexes[0]) for index in indexes[1:]):\n+                    if not (indexes.is_monotonic_increasing\n+                            or indexes.is_monotonic_decreasing):\n+                        raise ValueError(\"Resulting object does not have monotonic\"\n+                                         \" global indexes along dimension {}\"\n+                                         .format(dim))\n         concatenated_grouped_by_data_vars.append(concatenated)\n \n     return merge(concatenated_grouped_by_data_vars, compat=compat,\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\nindex b8f5640..7a5ea65 100644\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -28,6 +28,16 @@ def _infer_concat_order_from_coords(datasets):\n             if any((index is None for index in indexes)):\n                 raise ValueError('Every dimension needs a coordinate for inferring concatenation order')\n             if not all((index.equals(indexes[0]) for index in indexes[1:])):\n+                concat_dims.append(dim)\n+                if all((index.is_monotonic_increasing for index in indexes)):\n+                    ascending = True\n+                elif all((index.is_monotonic_decreasing for index in indexes)):\n+                    ascending = False\n+                else:\n+                    raise ValueError('Coordinate variable {} is neither monotonically increasing nor monotonically decreasing on all datasets'.format(dim))\n+                if any((index.size == 0 for index in indexes)):\n+                    raise ValueError('Cannot handle size zero dimensions')\n+                first_items = pd.Index([index.take([0]) for index in indexes])\n                 concat_dims.append(dim)\n                 if all((index.is_monotonic_increasing for index in indexes)):\n                     ascending = True\n@@ -118,8 +128,9 @@ def combine_by_coords(datasets, compat='no_conflicts', data_vars='all', coords='\n         for dim in concatenated.dims:\n             if dim in concatenated:\n                 indexes = concatenated.indexes.get(dim)\n-                if not (indexes.is_monotonic_increasing or indexes.is_monotonic_decreasing):\n-                    raise ValueError('Resulting object does not have monotonic global indexes along dimension {}'.format(dim))\n+                if not all((index.equals(indexes[0]) for index in indexes[1:])):\n+                    if not (indexes.is_monotonic_increasing or indexes.is_monotonic_decreasing):\n+                        raise ValueError('Resulting object does not have monotonic global indexes along dimension {}'.format(dim))\n         concatenated_grouped_by_data_vars.append(concatenated)\n     return merge(concatenated_grouped_by_data_vars, compat=compat, fill_value=fill_value)\n _CONCAT_DIM_DEFAULT = '__infer_concat_dim__'\n", "normalized_occurrence": 1}
