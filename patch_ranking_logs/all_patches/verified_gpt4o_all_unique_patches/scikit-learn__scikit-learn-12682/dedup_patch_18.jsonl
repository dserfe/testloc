{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-12682", "model_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex 8cfbe5f..a31e199 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -310,7 +310,7 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',\n                               algorithm=algorithm,\n                               regularization=regularization, copy_cov=copy_cov,\n                               init=init,\n-                              max_iter=max_iter,\n+                              max_iter=self.transform_max_iter,\n                               check_input=False,\n                               verbose=verbose,\n                               positive=positive)\n@@ -991,12 +991,14 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n \n     def __init__(self, dictionary, transform_algorithm='omp',\n                  transform_n_nonzero_coefs=None, transform_alpha=None,\n-                 split_sign=False, n_jobs=None, positive_code=False):\n+                 transform_max_iter=1000, split_sign=False, n_jobs=None,\n+                 positive_code=False):\n         self._set_sparse_coding_params(dictionary.shape[0],\n                                        transform_algorithm,\n                                        transform_n_nonzero_coefs,\n                                        transform_alpha, split_sign, n_jobs,\n                                        positive_code)\n+        self.transform_max_iter = transform_max_iter\n         self.components_ = dictionary\n \n     def fit(self, X, y=None):\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex 8a206a7..f7c83e4 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -83,7 +83,7 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars', n_\n         if regularization is None:\n             regularization = 1.0\n     if effective_n_jobs(n_jobs) == 1 or algorithm == 'threshold':\n-        code = _sparse_encode(X, dictionary, gram, cov=cov, algorithm=algorithm, regularization=regularization, copy_cov=copy_cov, init=init, max_iter=max_iter, check_input=False, verbose=verbose, positive=positive)\n+        code = _sparse_encode(X, dictionary, gram, cov=cov, algorithm=algorithm, regularization=regularization, copy_cov=copy_cov, init=init, max_iter=self.transform_max_iter, check_input=False, verbose=verbose, positive=positive)\n         return code\n     code = np.empty((n_samples, n_components))\n     slices = list(gen_even_slices(n_samples, effective_n_jobs(n_jobs)))\n@@ -284,8 +284,9 @@ class SparseCodingMixin(TransformerMixin):\n         return code\n class SparseCoder(BaseEstimator, SparseCodingMixin):\n     _required_parameters = ['dictionary']\n-    def __init__(self, dictionary, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, split_sign=False, n_jobs=None, positive_code=False):\n+    def __init__(self, dictionary, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, transform_max_iter=1000, split_sign=False, n_jobs=None, positive_code=False):\n         self._set_sparse_coding_params(dictionary.shape[0], transform_algorithm, transform_n_nonzero_coefs, transform_alpha, split_sign, n_jobs, positive_code)\n+        self.transform_max_iter = transform_max_iter\n         self.components_ = dictionary\n     def fit(self, X, y=None):\n         return self\n", "normalized_occurrence": 1}
