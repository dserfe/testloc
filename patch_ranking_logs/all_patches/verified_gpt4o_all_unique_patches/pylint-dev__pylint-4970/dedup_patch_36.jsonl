{"model_name_or_path": "agentless", "instance_id": "pylint-dev__pylint-4970", "model_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 79a566f..fe441cd 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -475,6 +475,8 @@ class Similar:\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n         index_to_lines_2: IndexToLines_T\n+        if self.min_lines == 0:\n+            return\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n \n@@ -833,19 +835,20 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         total = sum(len(lineset) for lineset in self.linesets)\n         duplicated = 0\n         stats = self.stats\n-        for num, couples in self._compute_sims():\n-            msg = []\n-            lineset = start_line = end_line = None\n-            for lineset, start_line, end_line in couples:\n-                msg.append(f\"=={lineset.name}:[{start_line}:{end_line}]\")\n-            msg.sort()\n-\n-            if lineset:\n-                for line in lineset.real_lines[start_line:end_line]:\n-                    msg.append(line.rstrip())\n-\n-            self.add_message(\"R0801\", args=(len(couples), \"\\n\".join(msg)))\n-            duplicated += num * (len(couples) - 1)\n+        if self.min_lines != 0:\n+            for num, couples in self._compute_sims():\n+                msg = []\n+                lineset = start_line = end_line = None\n+                for lineset, start_line, end_line in couples:\n+                    msg.append(f\"=={lineset.name}:[{start_line}:{end_line}]\")\n+                msg.sort()\n+\n+                if lineset:\n+                    for line in lineset.real_lines[start_line:end_line]:\n+                        msg.append(line.rstrip())\n+\n+                self.add_message(\"R0801\", args=(len(couples), \"\\n\".join(msg)))\n+                duplicated += num * (len(couples) - 1)\n         stats[\"nb_duplicated_lines\"] = duplicated\n         stats[\"percent_duplicated_lines\"] = total and duplicated * 100.0 / total\n \n", "occurrence": 1, "normalized_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 0997b2e..90a9234 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -189,6 +189,8 @@ class Similar:\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n         index_to_lines_2: IndexToLines_T\n+        if self.min_lines == 0:\n+            return\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n         hash_1: FrozenSet[LinesChunk] = frozenset(hash_to_index_1.keys())\n@@ -324,17 +326,18 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         total = sum((len(lineset) for lineset in self.linesets))\n         duplicated = 0\n         stats = self.stats\n-        for num, couples in self._compute_sims():\n-            msg = []\n-            lineset = start_line = end_line = None\n-            for lineset, start_line, end_line in couples:\n-                msg.append(f'=={lineset.name}:[{start_line}:{end_line}]')\n-            msg.sort()\n-            if lineset:\n-                for line in lineset.real_lines[start_line:end_line]:\n-                    msg.append(line.rstrip())\n-            self.add_message('R0801', args=(len(couples), '\\n'.join(msg)))\n-            duplicated += num * (len(couples) - 1)\n+        if self.min_lines != 0:\n+            for num, couples in self._compute_sims():\n+                msg = []\n+                lineset = start_line = end_line = None\n+                for lineset, start_line, end_line in couples:\n+                    msg.append(f'=={lineset.name}:[{start_line}:{end_line}]')\n+                msg.sort()\n+                if lineset:\n+                    for line in lineset.real_lines[start_line:end_line]:\n+                        msg.append(line.rstrip())\n+                self.add_message('R0801', args=(len(couples), '\\n'.join(msg)))\n+                duplicated += num * (len(couples) - 1)\n         stats['nb_duplicated_lines'] = duplicated\n         stats['percent_duplicated_lines'] = total and duplicated * 100.0 / total\n     def get_map_data(self):\n", "normalized_occurrence": 1}
