{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-25747", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 2f2ca70..b0f595c 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1277,10 +1277,13 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n         return self._hstack(Xs)\n \n     def _hstack(self, Xs):\n-        config = _get_output_config(\"transform\", self)\n-        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+        if all(isinstance(X, pd.DataFrame) for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            lengths = [len(X) for X in Xs]\n+            if len(set(lengths)) == 1:\n+                return pd.concat(Xs, axis=1)\n+            else:\n+                raise ValueError(f\"All DataFrames must have the same number of rows, but got lengths {lengths}.\")\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex f4194e0..546cb65 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -347,10 +347,13 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             return np.zeros((X.shape[0], 0))\n         return self._hstack(Xs)\n     def _hstack(self, Xs):\n-        config = _get_output_config('transform', self)\n-        if config['dense'] == 'pandas' and all((hasattr(X, 'iloc') for X in Xs)):\n+        if all((isinstance(X, pd.DataFrame) for X in Xs)):\n             pd = check_pandas_support('transform')\n-            return pd.concat(Xs, axis=1)\n+            lengths = [len(X) for X in Xs]\n+            if len(set(lengths)) == 1:\n+                return pd.concat(Xs, axis=1)\n+            else:\n+                raise ValueError(f'All DataFrames must have the same number of rows, but got lengths {lengths}.')\n         if any((sparse.issparse(f) for f in Xs)):\n             Xs = sparse.hstack(Xs).tocsr()\n         else:\n", "normalized_occurrence": 1}
