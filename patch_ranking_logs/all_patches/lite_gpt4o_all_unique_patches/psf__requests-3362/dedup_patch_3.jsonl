{"model_name_or_path": "agentless", "instance_id": "psf__requests-3362", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 58593f5..0d91d0f 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -657,8 +657,10 @@ class Response(object):\n         read into memory.  This is not necessarily the length of each item\n         returned as decoding can take place.\n \n+\n         If decode_unicode is True, content will be decoded using the best\n-        available encoding based on the response.\n+        available encoding based on the response. This means that each chunk\n+        yielded will be a Unicode string rather than a bytes string.\n         \"\"\"\n \n         def generate():\n@@ -695,7 +697,7 @@ class Response(object):\n         chunks = reused_chunks if self._content_consumed else stream_chunks\n \n         if decode_unicode:\n-            chunks = stream_decode_response_unicode(chunks, self)\n+            chunks = (chunk for chunk in stream_decode_response_unicode(chunks, self))\n \n         return chunks\n \n", "occurrence": 1, "normalized_patch": "diff --git a/requests/models.py b/requests/models.py\nindex d66e2b7..0afcac5 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -360,7 +360,7 @@ class Response(object):\n         stream_chunks = generate()\n         chunks = reused_chunks if self._content_consumed else stream_chunks\n         if decode_unicode:\n-            chunks = stream_decode_response_unicode(chunks, self)\n+            chunks = (chunk for chunk in stream_decode_response_unicode(chunks, self))\n         return chunks\n     def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):\n         pending = None\n", "normalized_occurrence": 1}
