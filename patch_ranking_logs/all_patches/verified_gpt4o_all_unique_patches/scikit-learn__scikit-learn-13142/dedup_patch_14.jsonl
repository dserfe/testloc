{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13142", "model_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex a853e4a..94aefc7 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -188,7 +188,8 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n         -------\n         self\n         \"\"\"\n-        self.fit_predict(X, y)\n+        labels = self.fit_predict(X, y)\n+        self.fit(X, y)\n         return self\n \n     def fit_predict(self, X, y=None):\n@@ -270,6 +271,9 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n                           % (init + 1), ConvergenceWarning)\n \n         self._set_parameters(best_params)\n+        # Perform a final fit with the best parameters to ensure consistency\n+        self._initialize(X, random_state)\n+        self._fit(X, y)\n         self.n_iter_ = best_n_iter\n         self.lower_bound_ = max_lower_bound\n \n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex 9518b16..2ed2e53 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -62,7 +62,8 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n     def _initialize(self, X, resp):\n         pass\n     def fit(self, X, y=None):\n-        self.fit_predict(X, y)\n+        labels = self.fit_predict(X, y)\n+        self.fit(X, y)\n         return self\n     def fit_predict(self, X, y=None):\n         X = _check_X(X, self.n_components, ensure_min_samples=2)\n@@ -97,6 +98,8 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n         if not self.converged_:\n             warnings.warn('Initialization %d did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.' % (init + 1), ConvergenceWarning)\n         self._set_parameters(best_params)\n+        self._initialize(X, random_state)\n+        self._fit(X, y)\n         self.n_iter_ = best_n_iter\n         self.lower_bound_ = max_lower_bound\n         return log_resp.argmax(axis=1)\n", "normalized_occurrence": 1}
