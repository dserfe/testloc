{"model_name_or_path": "agentless", "instance_id": "pylint-dev__pylint-4970", "model_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 79a566f..2f81f60 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -396,6 +396,8 @@ class Similar:\n         \"\"\"compute similarities in appended files\"\"\"\n         no_duplicates: Dict[int, List[Set[LinesChunkLimits_T]]] = defaultdict(list)\n \n+        if self.min_lines == 0:\n+            return []\n         for commonality in self._iter_sims():\n             num = commonality.cmn_lines_nb\n             lineset1 = commonality.fst_lset\n@@ -524,13 +526,15 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n-            if eff_cmn_nb > self.min_lines:\n+            if self.min_lines > 0 and eff_cmn_nb > self.min_lines:\n                 yield com\n \n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+        if self.min_lines == 0:\n+            return\n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n", "occurrence": 1, "normalized_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 0997b2e..6e2d911 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -141,6 +141,8 @@ class Similar:\n         self._display_sims(self._compute_sims())\n     def _compute_sims(self) -> List[Tuple[int, Set[LinesChunkLimits_T]]]:\n         no_duplicates: Dict[int, List[Set[LinesChunkLimits_T]]] = defaultdict(list)\n+        if self.min_lines == 0:\n+            return []\n         for commonality in self._iter_sims():\n             num = commonality.cmn_lines_nb\n             lineset1 = commonality.fst_lset\n@@ -207,9 +209,11 @@ class Similar:\n             nb_common_lines = cmn_l.effective_cmn_lines_nb\n             com = Commonality(cmn_lines_nb=nb_common_lines, fst_lset=lineset1, fst_file_start=cmn_l.first_file.start, fst_file_end=cmn_l.first_file.end, snd_lset=lineset2, snd_file_start=cmn_l.second_file.start, snd_file_end=cmn_l.second_file.end)\n             eff_cmn_nb = filter_noncode_lines(lineset1, start_index_1, lineset2, start_index_2, nb_common_lines)\n-            if eff_cmn_nb > self.min_lines:\n+            if self.min_lines > 0 and eff_cmn_nb > self.min_lines:\n                 yield com\n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        if self.min_lines == 0:\n+            return\n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1:]:\n                 yield from self._find_common(lineset, lineset2)\n", "normalized_occurrence": 1}
