{"model_name_or_path": "agentless_claude", "instance_id": "pytest-dev__pytest-7490", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 1316da9..94dee29 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -249,6 +249,14 @@ def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n     xfailed = item._store.get(xfailed_key, None)\n     if xfailed is None:\n         item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+    \n+    yield  # Run the test function\n+    \n+    # Re-evaluate after test in case markers were added during test execution\n+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+    if xfailed and not item.config.option.runxfail:\n+        if isinstance(item._evalxfail, Xfail):\n+            item._evalxfail = xfailed\n \n     if not item.config.option.runxfail:\n         if xfailed and not xfailed.run:\n", "occurrence": 1, "normalized_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex d85ae4c..6a4ed69 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -132,6 +132,11 @@ def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n     xfailed = item._store.get(xfailed_key, None)\n     if xfailed is None:\n         item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+    yield\n+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+    if xfailed and (not item.config.option.runxfail):\n+        if isinstance(item._evalxfail, Xfail):\n+            item._evalxfail = xfailed\n     if not item.config.option.runxfail:\n         if xfailed and (not xfailed.run):\n             xfail('[NOTRUN] ' + xfailed.reason)\n", "normalized_occurrence": 1}
