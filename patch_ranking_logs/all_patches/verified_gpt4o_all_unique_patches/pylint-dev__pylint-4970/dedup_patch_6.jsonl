{"model_name_or_path": "agentless", "instance_id": "pylint-dev__pylint-4970", "model_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 79a566f..2950e31 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -390,37 +390,39 @@ class Similar:\n \n     def run(self) -> None:\n         \"\"\"start looking for similarities and display results on stdout\"\"\"\n-        self._display_sims(self._compute_sims())\n+        if self.min_lines > 0:\n+            self._display_sims(self._compute_sims())\n \n     def _compute_sims(self) -> List[Tuple[int, Set[LinesChunkLimits_T]]]:\n         \"\"\"compute similarities in appended files\"\"\"\n         no_duplicates: Dict[int, List[Set[LinesChunkLimits_T]]] = defaultdict(list)\n \n-        for commonality in self._iter_sims():\n-            num = commonality.cmn_lines_nb\n-            lineset1 = commonality.fst_lset\n-            start_line_1 = commonality.fst_file_start\n-            end_line_1 = commonality.fst_file_end\n-            lineset2 = commonality.snd_lset\n-            start_line_2 = commonality.snd_file_start\n-            end_line_2 = commonality.snd_file_end\n-\n-            duplicate = no_duplicates[num]\n-            couples: Set[LinesChunkLimits_T]\n-            for couples in duplicate:\n-                if (lineset1, start_line_1, end_line_1) in couples or (\n-                    lineset2,\n-                    start_line_2,\n-                    end_line_2,\n-                ) in couples:\n-                    break\n-            else:\n-                duplicate.append(\n-                    {\n-                        (lineset1, start_line_1, end_line_1),\n-                        (lineset2, start_line_2, end_line_2),\n-                    }\n-                )\n+        if self.min_lines > 0:\n+            for commonality in self._iter_sims():\n+                num = commonality.cmn_lines_nb\n+                lineset1 = commonality.fst_lset\n+                start_line_1 = commonality.fst_file_start\n+                end_line_1 = commonality.fst_file_end\n+                lineset2 = commonality.snd_lset\n+                start_line_2 = commonality.snd_file_start\n+                end_line_2 = commonality.snd_file_end\n+\n+                duplicate = no_duplicates[num]\n+                couples: Set[LinesChunkLimits_T]\n+                for couples in duplicate:\n+                    if (lineset1, start_line_1, end_line_1) in couples or (\n+                        lineset2,\n+                        start_line_2,\n+                        end_line_2,\n+                    ) in couples:\n+                        break\n+                else:\n+                    duplicate.append(\n+                        {\n+                            (lineset1, start_line_1, end_line_1),\n+                            (lineset2, start_line_2, end_line_2),\n+                        }\n+                    )\n         sims: List[Tuple[int, Set[LinesChunkLimits_T]]] = []\n         ensembles: List[Set[LinesChunkLimits_T]]\n         for num, ensembles in no_duplicates.items():\n@@ -531,9 +533,10 @@ class Similar:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n-        for idx, lineset in enumerate(self.linesets[:-1]):\n-            for lineset2 in self.linesets[idx + 1 :]:\n-                yield from self._find_common(lineset, lineset2)\n+        if self.min_lines > 0:\n+            for idx, lineset in enumerate(self.linesets[:-1]):\n+                for lineset2 in self.linesets[idx + 1 :]:\n+                    yield from self._find_common(lineset, lineset2)\n \n     def get_map_data(self):\n         \"\"\"Returns the data we can use for a map/reduce process\n", "occurrence": 1, "normalized_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex 0997b2e..c560342 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -138,24 +138,26 @@ class Similar:\n         except UnicodeDecodeError:\n             pass\n     def run(self) -> None:\n-        self._display_sims(self._compute_sims())\n+        if self.min_lines > 0:\n+            self._display_sims(self._compute_sims())\n     def _compute_sims(self) -> List[Tuple[int, Set[LinesChunkLimits_T]]]:\n         no_duplicates: Dict[int, List[Set[LinesChunkLimits_T]]] = defaultdict(list)\n-        for commonality in self._iter_sims():\n-            num = commonality.cmn_lines_nb\n-            lineset1 = commonality.fst_lset\n-            start_line_1 = commonality.fst_file_start\n-            end_line_1 = commonality.fst_file_end\n-            lineset2 = commonality.snd_lset\n-            start_line_2 = commonality.snd_file_start\n-            end_line_2 = commonality.snd_file_end\n-            duplicate = no_duplicates[num]\n-            couples: Set[LinesChunkLimits_T]\n-            for couples in duplicate:\n-                if (lineset1, start_line_1, end_line_1) in couples or (lineset2, start_line_2, end_line_2) in couples:\n-                    break\n-            else:\n-                duplicate.append({(lineset1, start_line_1, end_line_1), (lineset2, start_line_2, end_line_2)})\n+        if self.min_lines > 0:\n+            for commonality in self._iter_sims():\n+                num = commonality.cmn_lines_nb\n+                lineset1 = commonality.fst_lset\n+                start_line_1 = commonality.fst_file_start\n+                end_line_1 = commonality.fst_file_end\n+                lineset2 = commonality.snd_lset\n+                start_line_2 = commonality.snd_file_start\n+                end_line_2 = commonality.snd_file_end\n+                duplicate = no_duplicates[num]\n+                couples: Set[LinesChunkLimits_T]\n+                for couples in duplicate:\n+                    if (lineset1, start_line_1, end_line_1) in couples or (lineset2, start_line_2, end_line_2) in couples:\n+                        break\n+                else:\n+                    duplicate.append({(lineset1, start_line_1, end_line_1), (lineset2, start_line_2, end_line_2)})\n         sims: List[Tuple[int, Set[LinesChunkLimits_T]]] = []\n         ensembles: List[Set[LinesChunkLimits_T]]\n         for num, ensembles in no_duplicates.items():\n@@ -210,9 +212,10 @@ class Similar:\n             if eff_cmn_nb > self.min_lines:\n                 yield com\n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n-        for idx, lineset in enumerate(self.linesets[:-1]):\n-            for lineset2 in self.linesets[idx + 1:]:\n-                yield from self._find_common(lineset, lineset2)\n+        if self.min_lines > 0:\n+            for idx, lineset in enumerate(self.linesets[:-1]):\n+                for lineset2 in self.linesets[idx + 1:]:\n+                    yield from self._find_common(lineset, lineset2)\n     def get_map_data(self):\n         return self.linesets\n     def combine_mapreduce_data(self, linesets_collection):\n", "normalized_occurrence": 1}
