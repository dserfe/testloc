{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13328", "model_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 774a22b..12b8e0e 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -56,6 +56,8 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n     w = w[:n_features]\n     n_samples = np.sum(sample_weight)\n \n+    # Ensure X is of type float\n+    X = X.astype(float)\n     # Calculate the values where |y - X'w -c / sigma| > epsilon\n     # The values above this threshold are outliers.\n     linear_loss = y - safe_sparse_dot(X, w)\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 81acf45..dc76f4a 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -14,6 +14,7 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n     sigma = w[-1]\n     w = w[:n_features]\n     n_samples = np.sum(sample_weight)\n+    X = X.astype(float)\n     linear_loss = y - safe_sparse_dot(X, w)\n     if fit_intercept:\n         linear_loss -= intercept\n", "normalized_occurrence": 8}
