{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13328", "model_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 774a22b..631fb55 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -58,6 +58,7 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n \n     # Calculate the values where |y - X'w -c / sigma| > epsilon\n     # The values above this threshold are outliers.\n+    X = X.astype(float)\n     linear_loss = y - safe_sparse_dot(X, w)\n     if fit_intercept:\n         linear_loss -= intercept\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 81acf45..dc76f4a 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -14,6 +14,7 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n     sigma = w[-1]\n     w = w[:n_features]\n     n_samples = np.sum(sample_weight)\n+    X = X.astype(float)\n     linear_loss = y - safe_sparse_dot(X, w)\n     if fit_intercept:\n         linear_loss -= intercept\n", "normalized_occurrence": 8}
