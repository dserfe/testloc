{"model_name_or_path": "agentless_claude", "instance_id": "sympy__sympy-24102", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 3e3bc62..418803a 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -615,6 +615,8 @@ class MathematicaParser:\n         tokens.extend(map(re.escape, tokens_escape))\n         tokens.append(\",\")\n         tokens.append(\"\\n\")\n+        # Add pattern for Unicode letters and other symbol characters\n+        tokens.append(r\"[^\\W\\d_]+\")  # Match one or more Unicode letter characters\n         tokenizer = re.compile(\"(\" + \"|\".join(tokens) + \")\")\n         self._regex_tokenizer = tokenizer\n         return self._regex_tokenizer\n", "occurrence": 1, "normalized_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 957d6fe..71a743e 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -241,6 +241,7 @@ class MathematicaParser:\n         tokens.extend(map(re.escape, tokens_escape))\n         tokens.append(',')\n         tokens.append('\\n')\n+        tokens.append('[^\\\\W\\\\d_]+')\n         tokenizer = re.compile('(' + '|'.join(tokens) + ')')\n         self._regex_tokenizer = tokenizer\n         return self._regex_tokenizer\n", "normalized_occurrence": 2}
