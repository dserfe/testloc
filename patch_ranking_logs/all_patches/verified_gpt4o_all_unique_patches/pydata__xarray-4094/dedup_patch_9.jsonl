{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-4094", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 1e17b93..7ae01c5 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3441,6 +3441,8 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n \n         \"\"\"\n         stacking_dims = tuple(dim for dim in self.dims if dim not in sample_dims)\n+        if not stacking_dims:\n+            stacking_dims = ('__dummy_dim__',)\n \n         for variable in self:\n             dims = self[variable].dims\n@@ -3454,7 +3456,7 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         def ensure_stackable(val):\n             assign_coords = {variable_dim: val.name}\n             for dim in stacking_dims:\n-                if dim not in val.dims:\n+                if stacking_dims != ('__dummy_dim__',) and dim not in val.dims:\n                     assign_coords[dim] = None\n \n             expand_dims = set(stacking_dims).difference(set(val.dims))\n@@ -3491,6 +3493,8 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         index = self.get_index(dim)\n         index = remove_unused_levels_categories(index)\n         full_idx = pd.MultiIndex.from_product(index.levels, names=index.names)\n+        if '__dummy_dim__' in full_idx.names:\n+            full_idx = full_idx.droplevel('__dummy_dim__')\n \n         # take a shortcut in case the MultiIndex was not modified.\n         if index.equals(full_idx):\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 21ef2a4..28f842d 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1140,6 +1140,8 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         return result\n     def to_stacked_array(self, new_dim: Hashable, sample_dims: Sequence[Hashable], variable_dim: str='variable', name: Hashable=None) -> 'DataArray':\n         stacking_dims = tuple((dim for dim in self.dims if dim not in sample_dims))\n+        if not stacking_dims:\n+            stacking_dims = ('__dummy_dim__',)\n         for variable in self:\n             dims = self[variable].dims\n             dims_include_sample_dims = set(sample_dims) <= set(dims)\n@@ -1148,7 +1150,7 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         def ensure_stackable(val):\n             assign_coords = {variable_dim: val.name}\n             for dim in stacking_dims:\n-                if dim not in val.dims:\n+                if stacking_dims != ('__dummy_dim__',) and dim not in val.dims:\n                     assign_coords[dim] = None\n             expand_dims = set(stacking_dims).difference(set(val.dims))\n             expand_dims.add(variable_dim)\n@@ -1167,6 +1169,8 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         index = self.get_index(dim)\n         index = remove_unused_levels_categories(index)\n         full_idx = pd.MultiIndex.from_product(index.levels, names=index.names)\n+        if '__dummy_dim__' in full_idx.names:\n+            full_idx = full_idx.droplevel('__dummy_dim__')\n         if index.equals(full_idx):\n             obj = self\n         else:\n", "normalized_occurrence": 1}
