{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13779", "model_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 858d868..b9758d1 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -76,24 +76,27 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n                              '; got %d weights, %d estimators'\n                              % (len(self.weights), len(self.estimators)))\n \n+        # Filter out None estimators\n+        valid_estimators = [(name, step) for name, step in self.estimators if step is not None]\n+\n         if sample_weight is not None:\n-            for name, step in self.estimators:\n+            for name, step in valid_estimators:\n                 if not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n \n-        names, clfs = zip(*self.estimators)\n+        names, clfs = zip(*valid_estimators)\n         self._validate_names(names)\n \n-        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n-        if n_isnone == len(self.estimators):\n+        n_isnone = np.sum([clf is None for _, clf in valid_estimators])\n+        if n_isnone == len(valid_estimators):\n             raise ValueError('All estimators are None. At least one is '\n                              'required!')\n \n         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n                 delayed(_parallel_fit_estimator)(clone(clf), X, y,\n                                                  sample_weight=sample_weight)\n-                for clf in clfs if clf is not None)\n+                for clf in clfs)\n \n         self.named_estimators_ = Bunch()\n         for k, e in zip(self.estimators, self.estimators_):\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex c17361f..5bee637 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -33,16 +33,17 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n             raise AttributeError('Invalid `estimators` attribute, `estimators` should be a list of (string, estimator) tuples')\n         if self.weights is not None and len(self.weights) != len(self.estimators):\n             raise ValueError('Number of `estimators` and weights must be equal; got %d weights, %d estimators' % (len(self.weights), len(self.estimators)))\n+        valid_estimators = [(name, step) for name, step in self.estimators if step is not None]\n         if sample_weight is not None:\n-            for name, step in self.estimators:\n+            for name, step in valid_estimators:\n                 if not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError(\"Underlying estimator '%s' does not support sample weights.\" % name)\n-        names, clfs = zip(*self.estimators)\n+        names, clfs = zip(*valid_estimators)\n         self._validate_names(names)\n-        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n-        if n_isnone == len(self.estimators):\n+        n_isnone = np.sum([clf is None for _, clf in valid_estimators])\n+        if n_isnone == len(valid_estimators):\n             raise ValueError('All estimators are None. At least one is required!')\n-        self.estimators_ = Parallel(n_jobs=self.n_jobs)((delayed(_parallel_fit_estimator)(clone(clf), X, y, sample_weight=sample_weight) for clf in clfs if clf is not None))\n+        self.estimators_ = Parallel(n_jobs=self.n_jobs)((delayed(_parallel_fit_estimator)(clone(clf), X, y, sample_weight=sample_weight) for clf in clfs))\n         self.named_estimators_ = Bunch()\n         for k, e in zip(self.estimators, self.estimators_):\n             self.named_estimators_[k[0]] = e\n", "normalized_occurrence": 1}
