{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-15512", "model_patch": "diff --git a/sklearn/cluster/_affinity_propagation.py b/sklearn/cluster/_affinity_propagation.py\nindex 0511594..c3eb402 100644\n--- a/sklearn/cluster/_affinity_propagation.py\n+++ b/sklearn/cluster/_affinity_propagation.py\n@@ -193,13 +193,15 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n             se = np.sum(e, axis=1)\n             unconverged = (np.sum((se == convergence_iter) + (se == 0))\n                            != n_samples)\n-            if (not unconverged and (K > 0)) or (it == max_iter):\n+            if not unconverged and K > 0:\n                 if verbose:\n                     print(\"Converged after %d iterations.\" % it)\n                 break\n-    else:\n-        if verbose:\n-            print(\"Did not converge\")\n+        elif it == max_iter - 1:\n+            if verbose:\n+                print(\"Did not converge\")\n+            E[:] = False  # Mark that the algorithm did not converge\n+            break\n \n     I = np.flatnonzero(E)\n     K = I.size  # Identify exemplars\n@@ -440,4 +442,4 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n         labels : ndarray, shape (n_samples,)\n             Cluster labels.\n         \"\"\"\n-        return super().fit_predict(X, y)\n+        return super().fit_predict(X, y)\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/cluster/_affinity_propagation.py b/sklearn/cluster/_affinity_propagation.py\nindex b441de5..58801df 100644\n--- a/sklearn/cluster/_affinity_propagation.py\n+++ b/sklearn/cluster/_affinity_propagation.py\n@@ -64,13 +64,15 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n         if it >= convergence_iter:\n             se = np.sum(e, axis=1)\n             unconverged = np.sum((se == convergence_iter) + (se == 0)) != n_samples\n-            if not unconverged and K > 0 or it == max_iter:\n+            if not unconverged and K > 0:\n                 if verbose:\n                     print('Converged after %d iterations.' % it)\n                 break\n-    else:\n-        if verbose:\n-            print('Did not converge')\n+        elif it == max_iter - 1:\n+            if verbose:\n+                print('Did not converge')\n+            E[:] = False\n+            break\n     I = np.flatnonzero(E)\n     K = I.size\n     if K > 0:\n", "normalized_occurrence": 1}
