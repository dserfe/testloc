{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-11281", "model_patch": "diff --git a/sklearn/mixture/gaussian_mixture.py b/sklearn/mixture/gaussian_mixture.py\nindex 67ca063..d4ff30c 100644\n--- a/sklearn/mixture/gaussian_mixture.py\n+++ b/sklearn/mixture/gaussian_mixture.py\n@@ -596,7 +596,56 @@ class GaussianMixture(BaseMixture):\n         self.means_init = means_init\n         self.precisions_init = precisions_init\n \n-    def _check_parameters(self, X):\n+    def fit(self, X, y=None):\n+        self._check_parameters(X)\n+        self._initialize_parameters(X)\n+        max_lower_bound = -np.infty\n+\n+        # EM algorithm\n+        for init in range(self.n_init):\n+            self._initialize(X, self._resp)\n+\n+            lower_bound = (-np.infty if self.warm_start\n+                           else -np.infty)\n+            for n_iter_ in range(self.max_iter):\n+                prev_lower_bound = lower_bound\n+\n+                log_prob_norm, log_resp = self._e_step(X)\n+                self._m_step(X, log_resp)\n+                lower_bound = self._compute_lower_bound(\n+                    log_resp, log_prob_norm)\n+\n+                change = lower_bound - prev_lower_bound\n+                if abs(change) < self.tol:\n+                    break\n+\n+            if lower_bound > max_lower_bound:\n+                max_lower_bound = lower_bound\n+                best_params = self._get_parameters()\n+                self.converged_ = (lower_bound - prev_lower_bound) < self.tol\n+\n+        self._set_parameters(best_params)\n+        self.lower_bound_ = max_lower_bound\n+        self.n_iter_ = n_iter_ + 1\n+\n+        self.labels_ = self.predict(X)\n+\n+        return self\n+\n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit the model to X and return the labels for the data.\n+\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_features)\n+            The input data.\n+\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Component labels.\n+        \"\"\"\n+        return self.fit(X, y).labels_\n         \"\"\"Check the Gaussian mixture parameters are well defined.\"\"\"\n         _, n_features = X.shape\n         if self.covariance_type not in ['spherical', 'tied', 'diag', 'full']:\n@@ -747,4 +796,4 @@ class GaussianMixture(BaseMixture):\n         aic : float\n             The lower the better.\n         \"\"\"\n-        return -2 * self.score(X) * X.shape[0] + 2 * self._n_parameters()\n+        return -2 * self.score(X) * X.shape[0] + 2 * self._n_parameters()\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/mixture/gaussian_mixture.py b/sklearn/mixture/gaussian_mixture.py\nindex ff762d7..05c4318 100644\n--- a/sklearn/mixture/gaussian_mixture.py\n+++ b/sklearn/mixture/gaussian_mixture.py\n@@ -122,7 +122,32 @@ class GaussianMixture(BaseMixture):\n         self.weights_init = weights_init\n         self.means_init = means_init\n         self.precisions_init = precisions_init\n-    def _check_parameters(self, X):\n+    def fit(self, X, y=None):\n+        self._check_parameters(X)\n+        self._initialize_parameters(X)\n+        max_lower_bound = -np.infty\n+        for init in range(self.n_init):\n+            self._initialize(X, self._resp)\n+            lower_bound = -np.infty if self.warm_start else -np.infty\n+            for n_iter_ in range(self.max_iter):\n+                prev_lower_bound = lower_bound\n+                log_prob_norm, log_resp = self._e_step(X)\n+                self._m_step(X, log_resp)\n+                lower_bound = self._compute_lower_bound(log_resp, log_prob_norm)\n+                change = lower_bound - prev_lower_bound\n+                if abs(change) < self.tol:\n+                    break\n+            if lower_bound > max_lower_bound:\n+                max_lower_bound = lower_bound\n+                best_params = self._get_parameters()\n+                self.converged_ = lower_bound - prev_lower_bound < self.tol\n+        self._set_parameters(best_params)\n+        self.lower_bound_ = max_lower_bound\n+        self.n_iter_ = n_iter_ + 1\n+        self.labels_ = self.predict(X)\n+        return self\n+    def fit_predict(self, X, y=None):\n+        return self.fit(X, y).labels_\n         _, n_features = X.shape\n         if self.covariance_type not in ['spherical', 'tied', 'diag', 'full']:\n             raise ValueError(\"Invalid value for 'covariance_type': %s 'covariance_type' should be in ['spherical', 'tied', 'diag', 'full']\" % self.covariance_type)\n", "normalized_occurrence": 1}
