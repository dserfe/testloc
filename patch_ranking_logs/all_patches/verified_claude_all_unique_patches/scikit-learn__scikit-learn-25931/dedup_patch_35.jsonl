{"model_name_or_path": "agentless_claude", "instance_id": "scikit-learn__scikit-learn-25931", "model_patch": "diff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex d995c25..a48d2be 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -288,17 +288,17 @@ class IsolationForest(OutlierMixin, BaseBagging):\n             Fitted estimator.\n         \"\"\"\n         self._validate_params()\n-        X = self._validate_data(X, accept_sparse=[\"csc\"], dtype=tree_dtype)\n-        if issparse(X):\n+        X_validated = self._validate_data(X, accept_sparse=[\"csc\"], dtype=tree_dtype)\n+        if issparse(X_validated):\n             # Pre-sort indices to avoid that each individual tree of the\n             # ensemble sorts the indices.\n-            X.sort_indices()\n+            X_validated.sort_indices()\n \n         rnd = check_random_state(self.random_state)\n-        y = rnd.uniform(size=X.shape[0])\n+        y = rnd.uniform(size=X_validated.shape[0])\n \n         # ensure that max_sample is in [1, n_samples]:\n-        n_samples = X.shape[0]\n+        n_samples = X_validated.shape[0]\n \n         if isinstance(self.max_samples, str) and self.max_samples == \"auto\":\n             max_samples = min(256, n_samples)\n@@ -320,7 +320,7 @@ class IsolationForest(OutlierMixin, BaseBagging):\n         self.max_samples_ = max_samples\n         max_depth = int(np.ceil(np.log2(max(max_samples, 2))))\n         super()._fit(\n-            X,\n+            X_validated,\n             y,\n             max_samples,\n             max_depth=max_depth,\n@@ -345,7 +345,7 @@ class IsolationForest(OutlierMixin, BaseBagging):\n             return self\n \n         # else, define offset_ wrt contamination parameter\n-        self.offset_ = np.percentile(self.score_samples(X), 100.0 * self.contamination)\n+        self.offset_ = np.percentile(self.score_samples(X_validated), 100.0 * self.contamination)\n \n         return self\n \n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex f9e64b9..47c5261 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -23,12 +23,12 @@ class IsolationForest(OutlierMixin, BaseBagging):\n         return {'prefer': 'threads'}\n     def fit(self, X, y=None, sample_weight=None):\n         self._validate_params()\n-        X = self._validate_data(X, accept_sparse=['csc'], dtype=tree_dtype)\n-        if issparse(X):\n-            X.sort_indices()\n+        X_validated = self._validate_data(X, accept_sparse=['csc'], dtype=tree_dtype)\n+        if issparse(X_validated):\n+            X_validated.sort_indices()\n         rnd = check_random_state(self.random_state)\n-        y = rnd.uniform(size=X.shape[0])\n-        n_samples = X.shape[0]\n+        y = rnd.uniform(size=X_validated.shape[0])\n+        n_samples = X_validated.shape[0]\n         if isinstance(self.max_samples, str) and self.max_samples == 'auto':\n             max_samples = min(256, n_samples)\n         elif isinstance(self.max_samples, numbers.Integral):\n@@ -41,12 +41,12 @@ class IsolationForest(OutlierMixin, BaseBagging):\n             max_samples = int(self.max_samples * X.shape[0])\n         self.max_samples_ = max_samples\n         max_depth = int(np.ceil(np.log2(max(max_samples, 2))))\n-        super()._fit(X, y, max_samples, max_depth=max_depth, sample_weight=sample_weight, check_input=False)\n+        super()._fit(X_validated, y, max_samples, max_depth=max_depth, sample_weight=sample_weight, check_input=False)\n         self._average_path_length_per_tree, self._decision_path_lengths = zip(*[(_average_path_length(tree.tree_.n_node_samples), tree.tree_.compute_node_depths()) for tree in self.estimators_])\n         if self.contamination == 'auto':\n             self.offset_ = -0.5\n             return self\n-        self.offset_ = np.percentile(self.score_samples(X), 100.0 * self.contamination)\n+        self.offset_ = np.percentile(self.score_samples(X_validated), 100.0 * self.contamination)\n         return self\n     def predict(self, X):\n         check_is_fitted(self)\n", "normalized_occurrence": 1}
