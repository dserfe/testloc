{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-3151", "model_patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\nindex fe3f23b..41ebca2 100644\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -68,40 +68,41 @@ def _infer_concat_order_from_coords(datasets):\n \n             # If dimension coordinate values are same on every dataset then\n             # should be leaving this dimension alone (it's just a \"bystander\")\n-            if not all(index.equals(indexes[0]) for index in indexes[1:]):\n-\n-                # Infer order datasets should be arranged in along this dim\n-                concat_dims.append(dim)\n-\n-                if all(index.is_monotonic_increasing for index in indexes):\n-                    ascending = True\n-                elif all(index.is_monotonic_decreasing for index in indexes):\n-                    ascending = False\n-                else:\n-                    raise ValueError(\"Coordinate variable {} is neither \"\n-                                     \"monotonically increasing nor \"\n-                                     \"monotonically decreasing on all datasets\"\n-                                     .format(dim))\n+            if all(index.equals(indexes[0]) for index in indexes[1:]):\n+                continue\n+\n+            # Infer order datasets should be arranged in along this dim\n+            concat_dims.append(dim)\n \n-                # Assume that any two datasets whose coord along dim starts\n-                # with the same value have the same coord values throughout.\n-                if any(index.size == 0 for index in indexes):\n-                    raise ValueError('Cannot handle size zero dimensions')\n-                first_items = pd.Index([index.take([0])\n-                                        for index in indexes])\n-\n-                # Sort datasets along dim\n-                # We want rank but with identical elements given identical\n-                # position indices - they should be concatenated along another\n-                # dimension, not along this one\n-                series = first_items.to_series()\n-                rank = series.rank(method='dense', ascending=ascending)\n-                order = rank.astype(int).values - 1\n-\n-                # Append positions along extra dimension to structure which\n-                # encodes the multi-dimensional concatentation order\n-                tile_ids = [tile_id + (position,) for tile_id, position\n-                            in zip(tile_ids, order)]\n+            if all(index.is_monotonic_increasing for index in indexes):\n+                ascending = True\n+            elif all(index.is_monotonic_decreasing for index in indexes):\n+                ascending = False\n+            else:\n+                raise ValueError(\"Coordinate variable {} is neither \"\n+                                 \"monotonically increasing nor \"\n+                                 \"monotonically decreasing on all datasets\"\n+                                 .format(dim))\n+\n+            # Assume that any two datasets whose coord along dim starts\n+            # with the same value have the same coord values throughout.\n+            if any(index.size == 0 for index in indexes):\n+                raise ValueError('Cannot handle size zero dimensions')\n+            first_items = pd.Index([index.take([0])\n+                                    for index in indexes])\n+\n+            # Sort datasets along dim\n+            # We want rank but with identical elements given identical\n+            # position indices - they should be concatenated along another\n+            # dimension, not along this one\n+            series = first_items.to_series()\n+            rank = series.rank(method='dense', ascending=ascending)\n+            order = rank.astype(int).values - 1\n+\n+            # Append positions along extra dimension to structure which\n+            # encodes the multi-dimensional concatentation order\n+            tile_ids = [tile_id + (position,) for tile_id, position\n+                        in zip(tile_ids, order)]\n \n     if len(datasets) > 1 and not concat_dims:\n         raise ValueError(\"Could not find any dimension coordinates to use to \"\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\nindex b8f5640..50d165c 100644\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -27,21 +27,22 @@ def _infer_concat_order_from_coords(datasets):\n             indexes = [ds.indexes.get(dim) for ds in datasets]\n             if any((index is None for index in indexes)):\n                 raise ValueError('Every dimension needs a coordinate for inferring concatenation order')\n-            if not all((index.equals(indexes[0]) for index in indexes[1:])):\n-                concat_dims.append(dim)\n-                if all((index.is_monotonic_increasing for index in indexes)):\n-                    ascending = True\n-                elif all((index.is_monotonic_decreasing for index in indexes)):\n-                    ascending = False\n-                else:\n-                    raise ValueError('Coordinate variable {} is neither monotonically increasing nor monotonically decreasing on all datasets'.format(dim))\n-                if any((index.size == 0 for index in indexes)):\n-                    raise ValueError('Cannot handle size zero dimensions')\n-                first_items = pd.Index([index.take([0]) for index in indexes])\n-                series = first_items.to_series()\n-                rank = series.rank(method='dense', ascending=ascending)\n-                order = rank.astype(int).values - 1\n-                tile_ids = [tile_id + (position,) for tile_id, position in zip(tile_ids, order)]\n+            if all((index.equals(indexes[0]) for index in indexes[1:])):\n+                continue\n+            concat_dims.append(dim)\n+            if all((index.is_monotonic_increasing for index in indexes)):\n+                ascending = True\n+            elif all((index.is_monotonic_decreasing for index in indexes)):\n+                ascending = False\n+            else:\n+                raise ValueError('Coordinate variable {} is neither monotonically increasing nor monotonically decreasing on all datasets'.format(dim))\n+            if any((index.size == 0 for index in indexes)):\n+                raise ValueError('Cannot handle size zero dimensions')\n+            first_items = pd.Index([index.take([0]) for index in indexes])\n+            series = first_items.to_series()\n+            rank = series.rank(method='dense', ascending=ascending)\n+            order = rank.astype(int).values - 1\n+            tile_ids = [tile_id + (position,) for tile_id, position in zip(tile_ids, order)]\n     if len(datasets) > 1 and (not concat_dims):\n         raise ValueError('Could not find any dimension coordinates to use to order the datasets for concatenation')\n     combined_ids = OrderedDict(zip(tile_ids, datasets))\n", "normalized_occurrence": 1}
