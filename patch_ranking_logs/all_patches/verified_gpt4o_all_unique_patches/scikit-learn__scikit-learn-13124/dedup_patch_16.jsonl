{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13124", "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex 1bd5697..9b25169 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -645,14 +645,19 @@ class StratifiedKFold(_BaseKFold):\n                            \" be less than n_splits=%d.\"\n                            % (min_groups, self.n_splits)), Warning)\n \n-        # pre-assign each sample to a test fold index using individual KFold\n-        # splitting strategies for each class so as to respect the balance of\n-        # classes\n-        # NOTE: Passing the data corresponding to ith class say X[y==class_i]\n-        # will break when the data is not 100% stratifiable for all classes.\n-        # So we pass np.zeroes(max(c, n_splits)) as data to the KFold\n+        if self.shuffle:\n+            for cls in np.unique(y):\n+                cls_idx = np.where(y == cls)[0]\n+                rng.shuffle(cls_idx)\n+                y[cls_idx] = y[cls_idx]\n+\n+        y = column_or_1d(y)\n+        n_samples = y.shape[0]\n+        unique_y, y_inversed = np.unique(y, return_inverse=True)\n+        y_counts = np.bincount(y_inversed)\n+\n         per_cls_cvs = [\n-            KFold(self.n_splits, shuffle=self.shuffle,\n+            KFold(self.n_splits, shuffle=False,\n                   random_state=rng).split(np.zeros(max(count, self.n_splits)))\n             for count in y_counts]\n \n@@ -660,11 +665,6 @@ class StratifiedKFold(_BaseKFold):\n         for test_fold_indices, per_cls_splits in enumerate(zip(*per_cls_cvs)):\n             for cls, (_, test_split) in zip(unique_y, per_cls_splits):\n                 cls_test_folds = test_folds[y == cls]\n-                # the test split can be too big because we used\n-                # KFold(...).split(X[:max(c, n_splits)]) when data is not 100%\n-                # stratifiable for all the classes\n-                # (we use a warning instead of raising an exception)\n-                # If this is the case, let's trim it:\n                 test_split = test_split[test_split < len(cls_test_folds)]\n                 cls_test_folds[test_split] = test_fold_indices\n                 test_folds[y == cls] = cls_test_folds\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex a142d27..83a4dc1 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -562,7 +562,16 @@ class StratifiedKFold(_BaseKFold):\n             raise ValueError('n_splits=%d cannot be greater than the number of members in each class.' % self.n_splits)\n         if self.n_splits > min_groups:\n             warnings.warn('The least populated class in y has only %d members, which is too few. The minimum number of members in any class cannot be less than n_splits=%d.' % (min_groups, self.n_splits), Warning)\n-        per_cls_cvs = [KFold(self.n_splits, shuffle=self.shuffle, random_state=rng).split(np.zeros(max(count, self.n_splits))) for count in y_counts]\n+        if self.shuffle:\n+            for cls in np.unique(y):\n+                cls_idx = np.where(y == cls)[0]\n+                rng.shuffle(cls_idx)\n+                y[cls_idx] = y[cls_idx]\n+        y = column_or_1d(y)\n+        n_samples = y.shape[0]\n+        unique_y, y_inversed = np.unique(y, return_inverse=True)\n+        y_counts = np.bincount(y_inversed)\n+        per_cls_cvs = [KFold(self.n_splits, shuffle=False, random_state=rng).split(np.zeros(max(count, self.n_splits))) for count in y_counts]\n         test_folds = np.zeros(n_samples, dtype=np.int)\n         for test_fold_indices, per_cls_splits in enumerate(zip(*per_cls_cvs)):\n             for cls, (_, test_split) in zip(unique_y, per_cls_splits):\n", "normalized_occurrence": 1}
