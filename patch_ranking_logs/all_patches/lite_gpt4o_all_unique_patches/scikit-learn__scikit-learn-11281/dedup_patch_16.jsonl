{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-11281", "model_patch": "diff --git a/sklearn/mixture/gaussian_mixture.py b/sklearn/mixture/gaussian_mixture.py\nindex 67ca063..6a87a94 100644\n--- a/sklearn/mixture/gaussian_mixture.py\n+++ b/sklearn/mixture/gaussian_mixture.py\n@@ -445,8 +445,8 @@ class GaussianMixture(BaseMixture):\n \n     Parameters\n     ----------\n-    n_components : int, defaults to 1.\n-        The number of mixture components.\n+    n_clusters : int, defaults to 1.\n+        The number of mixture components (clusters).\n \n     covariance_type : {'full', 'tied', 'diag', 'spherical'},\n             defaults to 'full'.\n@@ -634,9 +634,9 @@ class GaussianMixture(BaseMixture):\n             X, resp, self.reg_covar, self.covariance_type)\n         weights /= n_samples\n \n-        self.weights_ = (weights if self.weights_init is None\n-                         else self.weights_init)\n+        self.weights_ = weights if self.weights_init is None else self.weights_init\n         self.means_ = means if self.means_init is None else self.means_init\n+        self.labels_ = np.argmax(resp, axis=1)\n \n         if self.precisions_init is None:\n             self.covariances_ = covariances\n@@ -735,6 +735,21 @@ class GaussianMixture(BaseMixture):\n         return (-2 * self.score(X) * X.shape[0] +\n                 self._n_parameters() * np.log(X.shape[0]))\n \n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit the model to X and return the cluster labels.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Component labels.\n+        \"\"\"\n+        self.fit(X)\n+        return self.labels_\n+\n     def aic(self, X):\n         \"\"\"Akaike information criterion for the current model on the input X.\n \n@@ -747,4 +762,4 @@ class GaussianMixture(BaseMixture):\n         aic : float\n             The lower the better.\n         \"\"\"\n-        return -2 * self.score(X) * X.shape[0] + 2 * self._n_parameters()\n+        return -2 * self.score(X) * X.shape[0] + 2 * self._n_parameters()\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/mixture/gaussian_mixture.py b/sklearn/mixture/gaussian_mixture.py\nindex ff762d7..0f63461 100644\n--- a/sklearn/mixture/gaussian_mixture.py\n+++ b/sklearn/mixture/gaussian_mixture.py\n@@ -138,6 +138,7 @@ class GaussianMixture(BaseMixture):\n         weights /= n_samples\n         self.weights_ = weights if self.weights_init is None else self.weights_init\n         self.means_ = means if self.means_init is None else self.means_init\n+        self.labels_ = np.argmax(resp, axis=1)\n         if self.precisions_init is None:\n             self.covariances_ = covariances\n             self.precisions_cholesky_ = _compute_precision_cholesky(covariances, self.covariance_type)\n@@ -187,5 +188,8 @@ class GaussianMixture(BaseMixture):\n         return int(cov_params + mean_params + self.n_components - 1)\n     def bic(self, X):\n         return -2 * self.score(X) * X.shape[0] + self._n_parameters() * np.log(X.shape[0])\n+    def fit_predict(self, X, y=None):\n+        self.fit(X)\n+        return self.labels_\n     def aic(self, X):\n         return -2 * self.score(X) * X.shape[0] + 2 * self._n_parameters()\n\\ No newline at end of file\n", "normalized_occurrence": 1}
