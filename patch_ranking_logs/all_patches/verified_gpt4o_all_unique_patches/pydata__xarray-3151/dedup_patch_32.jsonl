{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-3151", "model_patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\nindex fe3f23b..e0cb1e7 100644\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -66,22 +66,22 @@ def _infer_concat_order_from_coords(datasets):\n                 raise ValueError(\"Every dimension needs a coordinate for \"\n                                  \"inferring concatenation order\")\n \n-            # If dimension coordinate values are same on every dataset then\n-            # should be leaving this dimension alone (it's just a \"bystander\")\n-            if not all(index.equals(indexes[0]) for index in indexes[1:]):\n-\n-                # Infer order datasets should be arranged in along this dim\n-                concat_dims.append(dim)\n-\n-                if all(index.is_monotonic_increasing for index in indexes):\n-                    ascending = True\n-                elif all(index.is_monotonic_decreasing for index in indexes):\n-                    ascending = False\n-                else:\n-                    raise ValueError(\"Coordinate variable {} is neither \"\n-                                     \"monotonically increasing nor \"\n-                                     \"monotonically decreasing on all datasets\"\n-                                     .format(dim))\n+            # Allow identical coordinate dimension values even if non-monotonic\n+            if all(index.equals(indexes[0]) for index in indexes):\n+                continue\n+\n+            # Infer order datasets should be arranged in along this dim\n+            concat_dims.append(dim)\n+\n+            if all(index.is_monotonic_increasing for index in indexes):\n+                ascending = True\n+            elif all(index.is_monotonic_decreasing for index in indexes):\n+                ascending = False\n+            else:\n+                raise ValueError(\"Coordinate variable {} is neither \"\n+                                 \"monotonically increasing nor \"\n+                                 \"monotonically decreasing on all datasets\"\n+                                 .format(dim))\n \n                 # Assume that any two datasets whose coord along dim starts\n                 # with the same value have the same coord values throughout.\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\nindex b8f5640..0d758c2 100644\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -27,14 +27,15 @@ def _infer_concat_order_from_coords(datasets):\n             indexes = [ds.indexes.get(dim) for ds in datasets]\n             if any((index is None for index in indexes)):\n                 raise ValueError('Every dimension needs a coordinate for inferring concatenation order')\n-            if not all((index.equals(indexes[0]) for index in indexes[1:])):\n-                concat_dims.append(dim)\n-                if all((index.is_monotonic_increasing for index in indexes)):\n-                    ascending = True\n-                elif all((index.is_monotonic_decreasing for index in indexes)):\n-                    ascending = False\n-                else:\n-                    raise ValueError('Coordinate variable {} is neither monotonically increasing nor monotonically decreasing on all datasets'.format(dim))\n+            if all((index.equals(indexes[0]) for index in indexes)):\n+                continue\n+            concat_dims.append(dim)\n+            if all((index.is_monotonic_increasing for index in indexes)):\n+                ascending = True\n+            elif all((index.is_monotonic_decreasing for index in indexes)):\n+                ascending = False\n+            else:\n+                raise ValueError('Coordinate variable {} is neither monotonically increasing nor monotonically decreasing on all datasets'.format(dim))\n                 if any((index.size == 0 for index in indexes)):\n                     raise ValueError('Cannot handle size zero dimensions')\n                 first_items = pd.Index([index.take([0]) for index in indexes])\n", "normalized_occurrence": 2}
