{"model_name_or_path": "agentless_claude", "instance_id": "pydata__xarray-4493", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 8003c0d..5eed401 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3880,34 +3880,7 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n                 result = result._unstack_once(dim, fill_value)\n         return result\n \n-    def update(self, other: \"CoercibleMapping\") -> \"Dataset\":\n-        \"\"\"Update this dataset's variables with those from another dataset.\n \n-        Parameters\n-        ----------\n-        other : Dataset or mapping\n-            Variables with which to update this dataset. One of:\n-\n-            - Dataset\n-            - mapping {var name: DataArray}\n-            - mapping {var name: Variable}\n-            - mapping {var name: (dimension name, array-like)}\n-            - mapping {var name: (tuple of dimension names, array-like)}\n-\n-\n-        Returns\n-        -------\n-        updated : Dataset\n-            Updated dataset.\n-\n-        Raises\n-        ------\n-        ValueError\n-            If any dimensions would have inconsistent sizes in the updated\n-            dataset.\n-        \"\"\"\n-        merge_result = dataset_update_method(self, other)\n-        return self._replace(inplace=True, **merge_result._asdict())\n \n     def merge(\n         self,\n", "occurrence": 1, "normalized_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 5bd37a8..e34c95d 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1252,9 +1252,6 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n             else:\n                 result = result._unstack_once(dim, fill_value)\n         return result\n-    def update(self, other: 'CoercibleMapping') -> 'Dataset':\n-        merge_result = dataset_update_method(self, other)\n-        return self._replace(inplace=True, **merge_result._asdict())\n     def merge(self, other: Union['CoercibleMapping', 'DataArray'], overwrite_vars: Union[Hashable, Iterable[Hashable]]=frozenset(), compat: str='no_conflicts', join: str='outer', fill_value: Any=dtypes.NA) -> 'Dataset':\n         other = other.to_dataset() if isinstance(other, xr.DataArray) else other\n         merge_result = dataset_merge_method(self, other, overwrite_vars=overwrite_vars, compat=compat, join=join, fill_value=fill_value)\n", "normalized_occurrence": 1}
