{"model_name_or_path": "agentless_claude", "instance_id": "psf__requests-3362", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 58593f5..0b1a9e6 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -688,11 +688,19 @@ class Response(object):\n         elif not isinstance(chunk_size, int):\n             raise TypeError(\"chunk_size must be an int, it is instead a %s.\" % type(chunk_size))\n         # simulate reading small chunks of the content\n-        reused_chunks = iter_slices(self._content, chunk_size)\n-\n-        stream_chunks = generate()\n-\n-        chunks = reused_chunks if self._content_consumed else stream_chunks\n+        if self._content_consumed:\n+            if decode_unicode and isinstance(self._content, str):\n+                # Content already decoded, just iterate chunks\n+                return iter_slices(self._content, chunk_size)\n+            elif decode_unicode and isinstance(self._content, bytes):\n+                # Decode consumed bytes\n+                chunks = iter_slices(self._content, chunk_size)\n+                return stream_decode_response_unicode(chunks, self)\n+            else:\n+                # Return unconsumed chunks\n+                return iter_slices(self._content, chunk_size)\n+        \n+        chunks = generate()\n \n         if decode_unicode:\n             chunks = stream_decode_response_unicode(chunks, self)\n", "occurrence": 1, "normalized_patch": "diff --git a/requests/models.py b/requests/models.py\nindex d66e2b7..bd80495 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -356,9 +356,15 @@ class Response(object):\n             raise StreamConsumedError()\n         elif not isinstance(chunk_size, int):\n             raise TypeError('chunk_size must be an int, it is instead a %s.' % type(chunk_size))\n-        reused_chunks = iter_slices(self._content, chunk_size)\n-        stream_chunks = generate()\n-        chunks = reused_chunks if self._content_consumed else stream_chunks\n+        if self._content_consumed:\n+            if decode_unicode and isinstance(self._content, str):\n+                return iter_slices(self._content, chunk_size)\n+            elif decode_unicode and isinstance(self._content, bytes):\n+                chunks = iter_slices(self._content, chunk_size)\n+                return stream_decode_response_unicode(chunks, self)\n+            else:\n+                return iter_slices(self._content, chunk_size)\n+        chunks = generate()\n         if decode_unicode:\n             chunks = stream_decode_response_unicode(chunks, self)\n         return chunks\n", "normalized_occurrence": 1}
