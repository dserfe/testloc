{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-10908", "model_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex 7e240fc..8d81730 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -953,6 +953,8 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n         if not hasattr(self, 'vocabulary_'):\n             self._validate_vocabulary()\n \n+        if not hasattr(self, 'vocabulary_'):\n+            self._validate_vocabulary()\n         self._check_vocabulary()\n \n         # use the same matrix-building strategy as fit_transform\n@@ -973,6 +975,8 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n         X_inv : list of arrays, len = n_samples\n             List of arrays of terms.\n         \"\"\"\n+        if not hasattr(self, 'vocabulary_'):\n+            self._validate_vocabulary()\n         self._check_vocabulary()\n \n         if sp.issparse(X):\n@@ -993,6 +997,8 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n \n     def get_feature_names(self):\n         \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n+        if not hasattr(self, 'vocabulary_'):\n+            self._validate_vocabulary()\n         self._check_vocabulary()\n \n         return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n", "occurrence": 3, "normalized_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex 583049b..9b6214d 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -347,12 +347,16 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n             raise ValueError('Iterable over raw text documents expected, string object received.')\n         if not hasattr(self, 'vocabulary_'):\n             self._validate_vocabulary()\n+        if not hasattr(self, 'vocabulary_'):\n+            self._validate_vocabulary()\n         self._check_vocabulary()\n         _, X = self._count_vocab(raw_documents, fixed_vocab=True)\n         if self.binary:\n             X.data.fill(1)\n         return X\n     def inverse_transform(self, X):\n+        if not hasattr(self, 'vocabulary_'):\n+            self._validate_vocabulary()\n         self._check_vocabulary()\n         if sp.issparse(X):\n             X = X.tocsr()\n@@ -364,6 +368,8 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n         inverse_vocabulary = terms[np.argsort(indices)]\n         return [inverse_vocabulary[X[i, :].nonzero()[1]].ravel() for i in range(n_samples)]\n     def get_feature_names(self):\n+        if not hasattr(self, 'vocabulary_'):\n+            self._validate_vocabulary()\n         self._check_vocabulary()\n         return [t for t, i in sorted(six.iteritems(self.vocabulary_), key=itemgetter(1))]\n def _make_int_array():\n", "normalized_occurrence": 3}
