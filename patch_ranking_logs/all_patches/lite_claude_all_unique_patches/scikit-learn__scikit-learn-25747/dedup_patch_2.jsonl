{"model_name_or_path": "agentless_claude", "instance_id": "scikit-learn__scikit-learn-25747", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 2f2ca70..0fbcde3 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1280,7 +1280,17 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            # Handle potentially different indices due to aggregation\n+            try:\n+                return pd.concat(Xs, axis=1)\n+            except ValueError:\n+                # If indices are different (e.g. due to aggregation), \n+                # use the index from the first non-empty DataFrame\n+                first_df = next(X for X in Xs if not X.empty)\n+                for i, X in enumerate(Xs):\n+                    if not X.empty and len(X.index) != len(first_df.index):\n+                        Xs[i] = X.reindex(first_df.index)\n+                return pd.concat(Xs, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\n", "occurrence": 1, "normalized_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex f4194e0..df06190 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -350,7 +350,14 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n         config = _get_output_config('transform', self)\n         if config['dense'] == 'pandas' and all((hasattr(X, 'iloc') for X in Xs)):\n             pd = check_pandas_support('transform')\n-            return pd.concat(Xs, axis=1)\n+            try:\n+                return pd.concat(Xs, axis=1)\n+            except ValueError:\n+                first_df = next((X for X in Xs if not X.empty))\n+                for i, X in enumerate(Xs):\n+                    if not X.empty and len(X.index) != len(first_df.index):\n+                        Xs[i] = X.reindex(first_df.index)\n+                return pd.concat(Xs, axis=1)\n         if any((sparse.issparse(f) for f in Xs)):\n             Xs = sparse.hstack(Xs).tocsr()\n         else:\n", "normalized_occurrence": 1}
